{
  "tasks": [
    {
      "id": 1,
      "status": "done",
      "priority": "high",
      "details": "1.  **Modify `src/worker.mjs`:** Ensure the `genAI` instance (initialized with `new GoogleGenerativeAI(env.GOOGLE_API_KEY)`) is passed as an argument to the `handleModels` function. This will align its signature with `handleCompletions` and `handleEmbeddings`.\n    ```javascript\n    // In handleRequest or similar, where handleModels is called\n    import { GoogleGenerativeAI } from '@google/generative-ai';\n    // ...\n    const genAI = new GoogleGenerativeAI(env.GOOGLE_API_KEY);\n    // ...\n    // Update the call to handleModels\n    // For example: handleModels(request, env, genAI);\n    ```\n2.  **Modify `src/handlers/models.mjs`:**\n    *   Update the function signature to accept the `genAI` instance.\n    *   Remove the direct `Workspace` call to `${BASE_URL}/${API_VERSION}/models`.\n    *   Remove the `import` and usage of `makeHeaders` from `../utils/auth.mjs`.\n    *   Call the appropriate model listing method on the `genAI` instance (e.g., `await genAI.listModels()`).\n    *   Adapt the existing transformation logic to iterate over the SDK response (`models` array from `genAI.listModels()`) and format it into the OpenAI-compatible model list structure. Ensure `id` is derived from `model.name` (e.g., `model.name.replace(\"models/\", \"\")`).\n    ```javascript\n    // src/handlers/models.mjs\n    export async function handleModels(request, env, genAI) {\n        // Remove direct Workspace fetch call and makeHeaders usage\n        // const headers = makeHeaders(env.GOOGLE_API_KEY); // REMOVE THIS\n        // const response = await fetch(`${BASE_URL}/${API_VERSION}/models`, { headers }); // REMOVE THIS\n\n        // Use genAI.listModels()\n        const { models } = await genAI.listModels(); // SDK returns { models: [...] }\n\n        // Adapt transformation logic to SDK's Model objects\n        const openAIModels = models.map(model => {\n            const id = model.name.replace(\"models/\", \"\");\n            return {\n                id: id,\n                object: \"model\",\n                created: Date.now(), // Or a fixed value if not available from SDK\n                owned_by: \"google\",\n                permission: [],\n                // Add other necessary fields like capabilities, token limits if available in SDK model object\n                // Example:\n                // capabilities: model.capabilities,\n                // input_token_limit: model.inputTokenLimit,\n                // output_token_limit: model.outputTokenLimit,\n            };\n        });\n\n        return new Response(JSON.stringify({ data: openAIModels, object: \"list\" }), {\n            headers: { 'Content-Type': 'application/json' }\n        });\n    }\n    ```",
      "dependencies": [],
      "testStrategy": "1.  Send a GET request to the `/models` endpoint of the Cloudflare worker.\n2.  Verify that the response is a valid JSON array of models in the OpenAI format.\n3.  Confirm that the `id` field for each model is correctly derived (e.g., `gemini-pro` from `models/gemini-pro`).\n4.  Inspect the worker's logs (if available) or use a debugger to confirm that the `genAI.listModels()` method was invoked and no direct `fetch` call to the Gemini `/models` endpoint was made.\n5.  Ensure `makeHeaders` is no longer imported or used in `src/handlers/models.mjs`.",
      "title": "Refactor Models Handler (src/handlers/models.mjs) to Use js-genai SDK",
      "description": "Refactor the `handleModels` function in `src/handlers/models.mjs` to use the `genAI.listModels()` method from the `@google/generative-ai` SDK instead of a direct `Workspace` call and custom header utility.",
      "subtasks": []
    },
    {
      "status": "done",
      "id": 2,
      "priority": "high",
      "title": "Align Request Transformation with js-genai Input Types",
      "details": "Review and modify functions in `src/transformers/request.mjs` to ensure their output matches js-genai SDK's typed interfaces. The `body` variable in handlers (`src/handlers/completions.mjs`, `src/handlers/embeddings.mjs`) should then be directly passable to SDK methods.\n\n**Key Refactoring Steps:**\n1.  **`transformMessages`:** Output `contents` array should contain `Content` objects, with `Part` objects for text, function calls, and function responses. Use the structure `{text: \"...\"}`, `{functionCall: {...}}`, `{functionResponse: {...}}}`.\n    ```javascript\n    // src/transformers/request.mjs\n    export function transformMessages(messages) {\n        const contents = [];\n        for (const msg of messages) {\n            const parts = [];\n            if (msg.content) {\n                parts.push({ text: msg.content }); // Matches Part interface for text\n            }\n            if (msg.tool_calls && msg.tool_calls.length > 0) {\n                for (const toolCall of msg.tool_calls) {\n                    parts.push({\n                        functionCall: {\n                            name: toolCall.function.name,\n                            args: toolCall.function.arguments // Ensure this is already parsed JSON\n                        }\n                    });\n                }\n            }\n            if (msg.role === \"tool\" && msg.tool_call_id && msg.content) {\n                parts.push({\n                    functionResponse: {\n                        name: msg.tool_call_id, // Assuming tool_call_id maps to function name for response\n                        response: {\n                            result: msg.content // Or parse if content is JSON string\n                        }\n                    }\n                });\n            }\n\n            if (msg.role === \"user\") {\n                contents.push({ role: \"user\", parts: parts }); // Matches Content interface\n            } else if (msg.role === \"assistant\") {\n                contents.push({ role: \"model\", parts: parts }); // Matches Content interface\n            }\n        }\n        return contents;\n    }\n    ```\n2.  **`transformConfig`:** Output `generationConfig` object should match js-genai's `GenerationConfig` interface (e.g., `temperature`, `topP`, `topK`, `maxOutputTokens`, `stopSequences`).\n    ```javascript\n    // src/transformers/request.mjs\n    export function transformConfig(openAiConfig) {\n        const generationConfig = {};\n        if (openAiConfig.temperature !== undefined) generationConfig.temperature = openAiConfig.temperature;\n        if (openAiConfig.top_p !== undefined) generationConfig.topP = openAiConfig.top_p;\n        if (openAiConfig.top_k !== undefined) generationConfig.topK = openAiConfig.top_k;\n        if (openAiConfig.max_tokens !== undefined) generationConfig.maxOutputTokens = openAiConfig.max_tokens;\n        if (openAiConfig.stop_sequences !== undefined) generationConfig.stopSequences = openAiConfig.stop_sequences;\n        return generationConfig; // Matches GenerationConfig interface\n    }\n    ```\n3.  **`transformTools`:** Output `tools` array should contain `Tool` objects, specifically `functionDeclarations` matching the `FunctionDeclaration` interface.\n    ```javascript\n    // src/transformers/request.mjs\n    export function transformTools(openAiTools) {\n        if (!openAiTools || openAiTools.length === 0) return undefined;\n        const tools = openAiTools.map(tool => {\n            if (tool.type === \"function\" && tool.function) {\n                return {\n                    functionDeclarations: [{\n                        name: tool.function.name,\n                        description: tool.function.description,\n                        parameters: tool.function.parameters // Ensure this matches Schema type\n                    }]\n                };\n            }\n            return null;\n        }).filter(Boolean);\n        return tools.length > 0 ? tools : undefined; // Matches Tool interface\n    }\n    ```\n4.  **`transformRequest`:** Aggregate these typed parts into a complete `GenerateContentRequest` (for completions) or `EmbedContentRequest` (for embeddings).\n    ```javascript\n    // src/transformers/request.mjs\n    export async function transformRequest(openAiRequest) {\n        const requestBody = {};\n        requestBody.contents = transformMessages(openAiRequest.messages);\n        requestBody.generationConfig = transformConfig(openAiRequest);\n        requestBody.tools = transformTools(openAiRequest.tools);\n        if (openAiRequest.input) { // For embeddings\n            requestBody.content = { parts: [{ text: openAiRequest.input }] };\n        }\n        return requestBody; // This will be GenerateContentRequest or EmbedContentRequest\n    }\n    ```",
      "description": "Modify request transformation functions in `src/transformers/request.mjs` to produce objects directly compatible with js-genai SDK input types (e.g., `GenerateContentRequest`, `EmbedContentRequest`, `Content`, `Part`, `GenerationConfig`, `Tool`).",
      "dependencies": [
        1
      ],
      "testStrategy": "1.  Run existing unit tests for `src/transformers/request.mjs` (if any) and ensure they pass.\n2.  Perform integration tests for `/chat/completions` and `/embeddings` endpoints.\n3.  Send various types of requests (text-only, with tools/functions, with different generation configs) to `/chat/completions`.\n4.  Send requests to `/embeddings`.\n5.  Verify that the responses are correct and match the expected output.\n6.  Use a debugger or logging to inspect the `body` object passed to `geminiModel.generateContent` or `geminiModel.embedContent` in the handlers, confirming it adheres to js-genai's `GenerateContentRequest` or `EmbedContentRequest` structure.",
      "subtasks": []
    },
    {
      "status": "done",
      "title": "Consume Typed SDK Responses in Transformers",
      "description": "Modify response transformation functions in `src/transformers/response.mjs` to directly accept and process the typed response objects returned by the js-genai SDK (e.g., `GenerateContentResponse`, `EmbedContentResponse`), eliminating the need for manual JSON parsing.",
      "dependencies": [
        2
      ],
      "details": "Identify that in `src/handlers/completions.mjs`, `response.response` (for non-streaming) is already the structured `GenerateContentResponse` from the SDK. Similarly for `src/handlers/embeddings.mjs`, `response` from `geminiEmbeddingsModel.embedContent()` is the structured `EmbedContentResponse`.\n\n**Key Refactoring Steps:**\n1.  Modify `processCompletionsResponse` in `src/transformers/response.mjs` to accept the `GenerateContentResponse` object directly as its `data` parameter (instead of needing `JSON.parse` on text).\n2.  Modify `processEmbeddingsResponse` to accept the `EmbedContentResponse` object directly as its `data` parameter.\n3.  Adapt the internal logic of these and other relevant functions (e.g., `transformCandidates`, `transformUsage`) to access fields from these typed SDK response objects instead of assuming generic JSON object structures.\n    ```javascript\n    // src/transformers/response.mjs\n    export function processCompletionsResponse(sdkResponse, modelName) {\n        // sdkResponse is already a GenerateContentResponse object\n        const choices = sdkResponse.candidates.map((candidate, index) => {\n            const message = {\n                role: \"assistant\",\n                content: candidate.content?.parts.map(part => part.text).join(\"\") || \"\",\n                tool_calls: candidate.content?.parts.filter(part => part.functionCall).map(part => ({\n                    id: `call_${Date.now()}_${index}`,\n                    type: \"function\",\n                    function: {\n                        name: part.functionCall.name,\n                        arguments: JSON.stringify(part.functionCall.args)\n                    }\n                })) || []\n            };\n\n            return {\n                index: index,\n                message: message,\n                finish_reason: candidate.finishReason || \"stop\"\n            };\n        });\n\n        const usage = {\n            prompt_tokens: sdkResponse.usageMetadata?.promptTokenCount || 0,\n            completion_tokens: sdkResponse.usageMetadata?.candidatesTokenCount || 0,\n            total_tokens: (sdkResponse.usageMetadata?.promptTokenCount || 0) + (sdkResponse.usageMetadata?.candidatesTokenCount || 0)\n        };\n\n        return {\n            id: `chatcmpl-${Date.now()}`,\n            object: \"chat.completion\",\n            created: Math.floor(Date.now() / 1000),\n            model: modelName,\n            choices: choices,\n            usage: usage\n        };\n    }\n\n    export function processEmbeddingsResponse(sdkResponse, modelName) {\n        // sdkResponse is already an EmbedContentResponse object\n        const embeddings = sdkResponse.embeddings.map(embedding => ({\n            object: \"embedding\",\n            embedding: embedding.values,\n            index: 0\n        }));\n\n        const usage = {\n            prompt_tokens: sdkResponse.usageMetadata?.promptTokenCount || 0,\n            total_tokens: sdkResponse.usageMetadata?.promptTokenCount || 0\n        };\n\n        return {\n            object: \"list\",\n            data: embeddings,\n            model: modelName,\n            usage: usage\n        };\n    }\n    ```",
      "id": 3,
      "testStrategy": "1.  Run existing unit tests for `src/transformers/response.mjs` (if any) and ensure they pass.\n2.  Perform integration tests for `/chat/completions` (non-streaming) and `/embeddings` endpoints.\n3.  Verify that the final OpenAI-formatted responses are correct and contain the expected data (e.g., message content, tool calls, embeddings, token usage).\n4.  Confirm that `JSON.parse` calls on direct SDK response objects are removed within these transformation functions.",
      "priority": "high",
      "subtasks": []
    },
    {
      "title": "Refactor Stream Parsing Logic in src/transformers/stream.mjs",
      "priority": "high",
      "id": 4,
      "dependencies": [
        3
      ],
      "status": "done",
      "details": "1.  **Modify `src/handlers/completions.mjs`:**\n    *   Recognize that `rawResponse` (which is `response.stream` from `geminiModel.generateContentStream()`) is already an `AsyncGenerator<StreamGenerateContentResponse>`.\n    *   Remove the first `TransformStream` that uses `parseStream` and `parseStreamFlush`.\n    *   Directly pipe the `rawResponse` (converted to a `ReadableStream`) to the `TransformStream` that uses `toOpenAiStream` and `toOpenAiStreamFlush`.\n    ```javascript\n    // src/handlers/completions.mjs\n    import { toOpenAiStream, toOpenAiStreamFlush } from '../transformers/stream.mjs';\n    // ...\n    async function handleCompletions(request, env, genAI) {\n        // ...\n        if (isStream) {\n            const geminiModel = genAI.getGenerativeModel({ model: modelId });\n            const rawResponse = await geminiModel.generateContentStream(body); // rawResponse is AsyncGenerator<StreamGenerateContentResponse>\n\n            // REMOVE THE FIRST TRANSFORMSTREAM THAT USES parseStream/parseStreamFlush\n            // const transformStream = new TransformStream({\n            //     transform: parseStream,\n            //     flush: parseStreamFlush\n            // });\n            // const openAiStream = rawResponse.stream.pipeThrough(transformStream); // REMOVE THIS LINE\n\n            const openAiStreamTransformer = new TransformStream({\n                transform: toOpenAiStream,\n                flush: toOpenAiStreamFlush\n            });\n\n            // Convert AsyncGenerator to ReadableStream for pipeThrough\n            const readableStream = new ReadableStream({\n                async start(controller) {\n                    for await (const chunk of rawResponse.stream) {\n                        controller.enqueue(chunk);\n                    }\n                    controller.close();\n                }\n            });\n\n            return new Response(readableStream.pipeThrough(openAiStreamTransformer), {\n                headers: {\n                    'Content-Type': 'text/event-stream',\n                    'Cache-Control': 'no-cache',\n                    'Connection': 'keep-alive',\n                    ...corsHeaders\n                }\n            });\n        }\n        // ...\n    }\n    ```\n2.  **Modify `src/transformers/stream.mjs`:**\n    *   Remove `parseStream` and `parseStreamFlush` functions.\n    *   Modify `toOpenAiStream`: Its first parameter (`chunk`) will now be a `StreamGenerateContentResponse` object directly. Remove `JSON.parse(line)` and adapt logic to access fields from this typed object.\n    ```javascript\n    // src/transformers/stream.mjs\n    // REMOVE parseStream and parseStreamFlush functions\n\n    export async function toOpenAiStream(chunk, controller) {\n        // chunk is now a StreamGenerateContentResponse object\n        const data = chunk;\n\n        const choices = [];\n        if (data.candidates && data.candidates.length > 0) {\n            data.candidates.forEach((candidate, index) => {\n                const message = {\n                    role: \"assistant\",\n                    content: candidate.content?.parts.map(part => part.text).join(\"\") || \"\",\n                    tool_calls: candidate.content?.parts.filter(part => part.functionCall).map(part => ({\n                        id: `call_${Date.now()}_${index}_stream`,\n                        type: \"function\",\n                        function: {\n                            name: part.functionCall.name,\n                            arguments: JSON.stringify(part.functionCall.args)\n                        }\n                    })) || []\n                };\n\n                choices.push({\n                    index: index,\n                    delta: message,\n                    finish_reason: candidate.finishReason || null\n                });\n            });\n        }\n\n        const openAiChunk = {\n            id: `chatcmpl-${Date.now()}`,\n            object: \"chat.completion.chunk\",\n            created: Math.floor(Date.now() / 1000),\n            model: \"gemini-pro\", // Or the actual model name\n            choices: choices\n        };\n\n        controller.enqueue(`data: ${JSON.stringify(openAiChunk)}\\n\\n`);\n    }\n\n    export function toOpenAiStreamFlush(controller) {\n        controller.enqueue(\"data: [DONE]\\n\\n\");\n    }\n    ```\n3.  **`src/constants/index.mjs` modification:**\n    *   Remove `RESPONSE_LINE_REGEX` if it's no longer used elsewhere.\n    ```javascript\n    // src/constants/index.mjs\n    // REMOVE: export const RESPONSE_LINE_REGEX = /data: (.*)/;\n    ```",
      "testStrategy": "1.  Send a streaming POST request to the `/chat/completions` endpoint.\n2.  Verify that the response is a valid Server-Sent Events (SSE) stream in the OpenAI format.\n3.  Confirm that the stream correctly delivers content chunks and a `[DONE]` message at the end.\n4.  Ensure that the custom SSE parsing logic (functions `parseStream`, `parseStreamFlush`, and constant `RESPONSE_LINE_REGEX`) is removed from the codebase.\n5.  Verify that `toOpenAiStream` directly processes `StreamGenerateContentResponse` objects without attempting `JSON.parse`.",
      "description": "Simplify stream handling by removing custom SSE parsing logic (`parseStream`, `parseStreamFlush`, `RESPONSE_LINE_REGEX`) and directly processing `StreamGenerateContentResponse` objects yielded by the js-genai SDK's `AsyncGenerator` in `src/transformers/stream.mjs`.",
      "subtasks": []
    },
    {
      "priority": "medium",
      "id": 5,
      "testStrategy": "1.  Verify that `src/utils/auth.mjs` no longer contains the `makeHeaders` function.\n2.  Perform integration tests for all API endpoints (`/models`, `/chat/completions`, `/embeddings`) to ensure they continue to function correctly and are authenticated.\n3.  Confirm that no other files attempt to import or use `makeHeaders`.\n4.  Check `src/constants/index.mjs` to ensure `API_CLIENT` is removed if it has no other consumers.",
      "details": "1.  **Delete `makeHeaders` function:** Remove the entire `makeHeaders` function from `src/utils/auth.mjs`.\n    ```javascript\n    // src/utils/auth.mjs\n    // REMOVE THE ENTIRE FUNCTION:\n    // export function makeHeaders(apiKey) {\n    //     return {\n    //         'x-goog-api-key': apiKey,\n    //         'x-goog-api-client': API_CLIENT,\n    //     };\n    // }\n    ```\n2.  **Remove imports and usages:** Remove any `import` statements for `makeHeaders` from other files (e.g., `src/handlers/models.mjs` after Task 1.1 is complete).\n    ```javascript\n    // Any file importing makeHeaders (e.g., src/handlers/models.mjs)\n    // REMOVE: import { makeHeaders } from '../utils/auth.mjs';\n    ```\n3.  **Remove `API_CLIENT` constant:** If the `API_CLIENT` constant in `src/constants/index.mjs` is no longer used by any other part of the application code after `makeHeaders` is removed, it can also be deleted.\n    ```javascript\n    // src/constants/index.mjs\n    // If API_CLIENT is only used by makeHeaders, REMOVE IT:\n    // export const API_CLIENT = '...';\n    ```",
      "title": "Remove Custom Header Factory (src/utils/auth.mjs)",
      "description": "Delete the `makeHeaders` function from `src/utils/auth.mjs` and remove any imports or usages of it, as the js-genai SDK automatically handles authentication headers.",
      "status": "in-progress",
      "dependencies": [
        1
      ],
      "subtasks": []
    }
  ]
}