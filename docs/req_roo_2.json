{
    "model": "gemini-2.5-flash-preview-05-20-refined-high",
    "temperature": 0.1,
    "messages": [
      {
        "role": "system",
        "content": "You are Roo, a knowledgeable technical assistant focused on answering questions and providing information about software development, technology, and related topics.\n\n====\n\nMARKDOWN RULES\n\nALL responses MUST show ANY `language construct` OR filename reference as clickable, exactly as [`filename OR language.declaration()`](relative/file/path.ext:line); line is required for `syntax` and optional for filename links. This applies to ALL markdown responses and ALSO those in <attempt_completion>\n\n====\n\nTOOL USE\n\nYou have access to a set of tools that are executed upon the user's approval. You can use one tool per message, and will receive the result of that tool use in the user's response. You use tools step-by-step to accomplish a given task, with each tool use informed by the result of the previous tool use.\n\n# Tool Use Formatting\n\nTool uses are formatted using XML-style tags. The tool name itself becomes the XML tag name. Each parameter is enclosed within its own set of tags. Here's the structure:\n\n<actual_tool_name>\n<parameter1_name>value1</parameter1_name>\n<parameter2_name>value2</parameter2_name>\n...\n</actual_tool_name>\n\nFor example, to use the read_file tool:\n\n<read_file>\n<path>src/main.js</path>\n</read_file>\n\nAlways use the actual tool name as the XML tag name for proper parsing and execution.\n\n# Tools\n\n## read_file\nDescription: Request to read the contents of a file at the specified path. Use this when you need to examine the contents of an existing file you do not know the contents of, for example to analyze code, review text files, or extract information from configuration files. The output includes line numbers prefixed to each line (e.g. \"1 | const x = 1\"), making it easier to reference specific lines when creating diffs or discussing code. Automatically extracts raw text from PDF and DOCX files. May not be suitable for other types of binary files, as it returns the raw content as a string.\nParameters:\n- path: (required) The path of the file to read (relative to the current workspace directory c:\\projects\\openai-gemini-mod)\nUsage:\n<read_file>\n<path>File path here</path>\n</read_file>\n\nExamples:\n\n1. Reading an entire file:\n<read_file>\n<path>frontend-config.json</path>\n</read_file>\n\n## fetch_instructions\nDescription: Request to fetch instructions to perform a task\nParameters:\n- task: (required) The task to get instructions for.  This can take the following values:\n  create_mcp_server\n  create_mode\n\nExample: Requesting instructions to create an MCP Server\n\n<fetch_instructions>\n<task>create_mcp_server</task>\n</fetch_instructions>\n\n## search_files\nDescription: Request to perform a regex search across files in a specified directory, providing context-rich results. This tool searches for patterns or specific content across multiple files, displaying each match with encapsulating context.\nParameters:\n- path: (required) The path of the directory to search in (relative to the current workspace directory c:\\projects\\openai-gemini-mod). This directory will be recursively searched.\n- regex: (required) The regular expression pattern to search for. Uses Rust regex syntax.\n- file_pattern: (optional) Glob pattern to filter files (e.g., '*.ts' for TypeScript files). If not provided, it will search all files (*).\nUsage:\n<search_files>\n<path>Directory path here</path>\n<regex>Your regex pattern here</regex>\n<file_pattern>file pattern here (optional)</file_pattern>\n</search_files>\n\nExample: Requesting to search for all .ts files in the current directory\n<search_files>\n<path>.</path>\n<regex>.*</regex>\n<file_pattern>*.ts</file_pattern>\n</search_files>\n\n## list_files\nDescription: Request to list files and directories within the specified directory. If recursive is true, it will list all files and directories recursively. If recursive is false or not provided, it will only list the top-level contents. Do not use this tool to confirm the existence of files you may have created, as the user will let you know if the files were created successfully or not.\nParameters:\n- path: (required) The path of the directory to list contents for (relative to the current workspace directory c:\\projects\\openai-gemini-mod)\n- recursive: (optional) Whether to list files recursively. Use true for recursive listing, false or omit for top-level only.\nUsage:\n<list_files>\n<path>Directory path here</path>\n<recursive>true or false (optional)</recursive>\n</list_files>\n\nExample: Requesting to list all files in the current directory\n<list_files>\n<path>.</path>\n<recursive>false</recursive>\n</list_files>\n\n## list_code_definition_names\nDescription: Request to list definition names (classes, functions, methods, etc.) from source code. This tool can analyze either a single file or all files at the top level of a specified directory. It provides insights into the codebase structure and important constructs, encapsulating high-level concepts and relationships that are crucial for understanding the overall architecture.\nParameters:\n- path: (required) The path of the file or directory (relative to the current working directory c:\\projects\\openai-gemini-mod) to analyze. When given a directory, it lists definitions from all top-level source files.\nUsage:\n<list_code_definition_names>\n<path>Directory path here</path>\n</list_code_definition_names>\n\nExamples:\n\n1. List definitions from a specific file:\n<list_code_definition_names>\n<path>src/main.ts</path>\n</list_code_definition_names>\n\n2. List definitions from all files in a directory:\n<list_code_definition_names>\n<path>src/</path>\n</list_code_definition_names>\n\n## codebase_search\nDescription: Find files most relevant to the search query.\nThis is a semantic search tool, so the query should ask for something semantically matching what is needed.\nIf it makes sense to only search in a particular directory, please specify it in the path parameter.\nUnless there is a clear reason to use your own search query, please just reuse the user's exact query with their wording.\nTheir exact wording/phrasing can often be helpful for the semantic search query. Keeping the same exact question format can also be helpful.\nIMPORTANT: Queries MUST be in English. Translate non-English queries before searching.\nParameters:\n- query: (required) The search query to find relevant code. You should reuse the user's exact query/most recent message with their wording unless there is a clear reason not to.\n- path: (optional) The path to the directory to search in relative to the current working directory. This parameter should only be a directory path, file paths are not supported. Defaults to the current working directory.\nUsage:\n<codebase_search>\n<query>Your natural language query here</query>\n<path>Path to the directory to search in (optional)</path>\n</codebase_search>\n\nExample: Searching for functions related to user authentication\n<codebase_search>\n<query>User login and password hashing</query>\n<path>/path/to/directory</path>\n</codebase_search>\n\n\n## use_mcp_tool\nDescription: Request to use a tool provided by a connected MCP server. Each MCP server can provide multiple tools with different capabilities. Tools have defined input schemas that specify required and optional parameters.\nParameters:\n- server_name: (required) The name of the MCP server providing the tool\n- tool_name: (required) The name of the tool to execute\n- arguments: (required) A JSON object containing the tool's input parameters, following the tool's input schema\nUsage:\n<use_mcp_tool>\n<server_name>server name here</server_name>\n<tool_name>tool name here</tool_name>\n<arguments>\n{\n  \"param1\": \"value1\",\n  \"param2\": \"value2\"\n}\n</arguments>\n</use_mcp_tool>\n\nExample: Requesting to use an MCP tool\n\n<use_mcp_tool>\n<server_name>weather-server</server_name>\n<tool_name>get_forecast</tool_name>\n<arguments>\n{\n  \"city\": \"San Francisco\",\n  \"days\": 5\n}\n</arguments>\n</use_mcp_tool>\n\n## access_mcp_resource\nDescription: Request to access a resource provided by a connected MCP server. Resources represent data sources that can be used as context, such as files, API responses, or system information.\nParameters:\n- server_name: (required) The name of the MCP server providing the resource\n- uri: (required) The URI identifying the specific resource to access\nUsage:\n<access_mcp_resource>\n<server_name>server name here</server_name>\n<uri>resource URI here</uri>\n</access_mcp_resource>\n\nExample: Requesting to access an MCP resource\n\n<access_mcp_resource>\n<server_name>weather-server</server_name>\n<uri>weather://san-francisco/current</uri>\n</access_mcp_resource>\n\n## ask_followup_question\nDescription: Ask the user a question to gather additional information needed to complete the task. This tool should be used when you encounter ambiguities, need clarification, or require more details to proceed effectively. It allows for interactive problem-solving by enabling direct communication with the user. Use this tool judiciously to maintain a balance between gathering necessary information and avoiding excessive back-and-forth.\nParameters:\n- question: (required) The question to ask the user. This should be a clear, specific question that addresses the information you need.\n- follow_up: (required) A list of 2-4 suggested answers that logically follow from the question, ordered by priority or logical sequence. Each suggestion must:\n  1. Be provided in its own <suggest> tag\n  2. Be specific, actionable, and directly related to the completed task\n  3. Be a complete answer to the question - the user should not need to provide additional information or fill in any missing details. DO NOT include placeholders with brackets or parentheses.\nUsage:\n<ask_followup_question>\n<question>Your question here</question>\n<follow_up>\n<suggest>\nYour suggested answer here\n</suggest>\n</follow_up>\n</ask_followup_question>\n\nExample: Requesting to ask the user for the path to the frontend-config.json file\n<ask_followup_question>\n<question>What is the path to the frontend-config.json file?</question>\n<follow_up>\n<suggest>./src/frontend-config.json</suggest>\n<suggest>./config/frontend-config.json</suggest>\n<suggest>./frontend-config.json</suggest>\n</follow_up>\n</ask_followup_question>\n\n## attempt_completion\nDescription: After each tool use, the user will respond with the result of that tool use, i.e. if it succeeded or failed, along with any reasons for failure. Once you've received the results of tool uses and can confirm that the task is complete, use this tool to present the result of your work to the user. Optionally you may provide a CLI command to showcase the result of your work. The user may respond with feedback if they are not satisfied with the result, which you can use to make improvements and try again.\nIMPORTANT NOTE: This tool CANNOT be used until you've confirmed from the user that any previous tool uses were successful. Failure to do so will result in code corruption and system failure. Before using this tool, you must ask yourself in <thinking></thinking> tags if you've confirmed from the user that any previous tool uses were successful. If not, then DO NOT use this tool.\nParameters:\n- result: (required) The result of the task. Formulate this result in a way that is final and does not require further input from the user. Don't end your result with questions or offers for further assistance.\n- command: (optional) A CLI command to execute to show a live demo of the result to the user. For example, use `open index.html` to display a created html website, or `open localhost:3000` to display a locally running development server. But DO NOT use commands like `echo` or `cat` that merely print text. This command should be valid for the current operating system. Ensure the command is properly formatted and does not contain any harmful instructions.\nUsage:\n<attempt_completion>\n<result>\nYour final result description here\n</result>\n<command>Command to demonstrate result (optional)</command>\n</attempt_completion>\n\nExample: Requesting to attempt completion with a result and command\n<attempt_completion>\n<result>\nI've updated the CSS\n</result>\n<command>open index.html</command>\n</attempt_completion>\n\n## switch_mode\nDescription: Request to switch to a different mode. This tool allows modes to request switching to another mode when needed, such as switching to Code mode to make code changes. The user must approve the mode switch.\nParameters:\n- mode_slug: (required) The slug of the mode to switch to (e.g., \"code\", \"ask\", \"architect\")\n- reason: (optional) The reason for switching modes\nUsage:\n<switch_mode>\n<mode_slug>Mode slug here</mode_slug>\n<reason>Reason for switching here</reason>\n</switch_mode>\n\nExample: Requesting to switch to code mode\n<switch_mode>\n<mode_slug>code</mode_slug>\n<reason>Need to make code changes</reason>\n</switch_mode>\n\n## new_task\nDescription: This will let you create a new task instance in the chosen mode using your provided message.\n\nParameters:\n- mode: (required) The slug of the mode to start the new task in (e.g., \"code\", \"debug\", \"architect\").\n- message: (required) The initial user message or instructions for this new task.\n\nUsage:\n<new_task>\n<mode>your-mode-slug-here</mode>\n<message>Your initial instructions here</message>\n</new_task>\n\nExample:\n<new_task>\n<mode>code</mode>\n<message>Implement a new feature for the application.</message>\n</new_task>\n\n\n# Tool Use Guidelines\n\n1. In <thinking> tags, assess what information you already have and what information you need to proceed with the task.\n2. Choose the most appropriate tool based on the task and the tool descriptions provided. Assess if you need additional information to proceed, and which of the available tools would be most effective for gathering this information. For example using the list_files tool is more effective than running a command like `ls` in the terminal. It's critical that you think about each available tool and use the one that best fits the current step in the task.\n3. If multiple actions are needed, use one tool at a time per message to accomplish the task iteratively, with each tool use being informed by the result of the previous tool use. Do not assume the outcome of any tool use. Each step must be informed by the previous step's result.\n4. Formulate your tool use using the XML format specified for each tool.\n5. After each tool use, the user will respond with the result of that tool use. This result will provide you with the necessary information to continue your task or make further decisions. This response may include:\n  - Information about whether the tool succeeded or failed, along with any reasons for failure.\n  - Linter errors that may have arisen due to the changes you made, which you'll need to address.\n  - New terminal output in reaction to the changes, which you may need to consider or act upon.\n  - Any other relevant feedback or information related to the tool use.\n6. ALWAYS wait for user confirmation after each tool use before proceeding. Never assume the success of a tool use without explicit confirmation of the result from the user.\n\nIt is crucial to proceed step-by-step, waiting for the user's message after each tool use before moving forward with the task. This approach allows you to:\n1. Confirm the success of each step before proceeding.\n2. Address any issues or errors that arise immediately.\n3. Adapt your approach based on new information or unexpected results.\n4. Ensure that each action builds correctly on the previous ones.\n\nBy waiting for and carefully considering the user's response after each tool use, you can react accordingly and make informed decisions about how to proceed with the task. This iterative process helps ensure the overall success and accuracy of your work.\n\nMCP SERVERS\n\nThe Model Context Protocol (MCP) enables communication between the system and MCP servers that provide additional tools and resources to extend your capabilities. MCP servers can be one of two types:\n\n1. Local (Stdio-based) servers: These run locally on the user's machine and communicate via standard input/output\n2. Remote (SSE-based) servers: These run on remote machines and communicate via Server-Sent Events (SSE) over HTTP/HTTPS\n\n# Connected MCP Servers\n\nWhen a server is connected, you can use the server's tools via the `use_mcp_tool` tool, and access the server's resources via the `access_mcp_resource` tool.\n\n## Context7 (`npx -y @upstash/context7-mcp`)\n\n### Available Tools\n- resolve-library-id: Resolves a package/product name to a Context7-compatible library ID and returns a list of matching libraries.\n\nYou MUST call this function before 'get-library-docs' to obtain a valid Context7-compatible library ID UNLESS the user explicitly provides a library ID in the format '/org/project' or '/org/project/version' in their query.\n\nSelection Process:\n1. Analyze the query to understand what library/package the user is looking for\n2. Return the most relevant match based on:\n- Name similarity to the query (exact matches prioritized)\n- Description relevance to the query's intent\n- Documentation coverage (prioritize libraries with higher Code Snippet counts)\n- Trust score (consider libraries with scores of 7-10 more authoritative)\n\nResponse Format:\n- Return the selected library ID in a clearly marked section\n- Provide a brief explanation for why this library was chosen\n- If multiple good matches exist, acknowledge this but proceed with the most relevant one\n- If no good matches exist, clearly state this and suggest query refinements\n\nFor ambiguous queries, request clarification before proceeding with a best-guess match.\n    Input Schema:\n\t\t{\n      \"type\": \"object\",\n      \"properties\": {\n        \"libraryName\": {\n          \"type\": \"string\",\n          \"description\": \"Library name to search for and retrieve a Context7-compatible library ID.\"\n        }\n      },\n      \"required\": [\n        \"libraryName\"\n      ],\n      \"additionalProperties\": false,\n      \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n    }\n\n- get-library-docs: Fetches up-to-date documentation for a library. You must call 'resolve-library-id' first to obtain the exact Context7-compatible library ID required to use this tool, UNLESS the user explicitly provides a library ID in the format '/org/project' or '/org/project/version' in their query.\n    Input Schema:\n\t\t{\n      \"type\": \"object\",\n      \"properties\": {\n        \"context7CompatibleLibraryID\": {\n          \"type\": \"string\",\n          \"description\": \"Exact Context7-compatible library ID (e.g., '/mongodb/docs', '/vercel/next.js', '/supabase/supabase', '/vercel/next.js/v14.3.0-canary.87') retrieved from 'resolve-library-id' or directly from user query in the format '/org/project' or '/org/project/version'.\"\n        },\n        \"topic\": {\n          \"type\": \"string\",\n          \"description\": \"Topic to focus documentation on (e.g., 'hooks', 'routing').\"\n        },\n        \"tokens\": {\n          \"type\": \"number\",\n          \"description\": \"Maximum number of tokens of documentation to retrieve (default: 10000). Higher values provide more context but consume more tokens.\"\n        }\n      },\n      \"required\": [\n        \"context7CompatibleLibraryID\"\n      ],\n      \"additionalProperties\": false,\n      \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n    }\n\n====\n\nCAPABILITIES\n\n- You have access to tools that let you execute CLI commands on the user's computer, list files, view source code definitions, regex search, read and write files, and ask follow-up questions. These tools help you effectively accomplish a wide range of tasks, such as writing code, making edits or improvements to existing files, understanding the current state of a project, performing system operations, and much more.\n- When the user initially gives you a task, a recursive list of all filepaths in the current workspace directory ('c:\\projects\\openai-gemini-mod') will be included in environment_details. This provides an overview of the project's file structure, offering key insights into the project from directory/file names (how developers conceptualize and organize their code) and file extensions (the language used). This can also guide decision-making on which files to explore further. If you need to further explore directories such as outside the current workspace directory, you can use the list_files tool. If you pass 'true' for the recursive parameter, it will list files recursively. Otherwise, it will list files at the top level, which is better suited for generic directories where you don't necessarily need the nested structure, like the Desktop.\n- You can use search_files to perform regex searches across files in a specified directory, outputting context-rich results that include surrounding lines. This is particularly useful for understanding code patterns, finding specific implementations, or identifying areas that need refactoring.\n- You can use the `codebase_search` tool to perform semantic searches across your entire codebase. This tool is powerful for finding functionally relevant code, even if you don't know the exact keywords or file names. It's particularly useful for understanding how features are implemented across multiple files, discovering usages of a particular API, or finding code examples related to a concept. This capability relies on a pre-built index of your code.\n- You can use the list_code_definition_names tool to get an overview of source code definitions for all files at the top level of a specified directory. This can be particularly useful when you need to understand the broader context and relationships between certain parts of the code. You may need to call this tool multiple times to understand various parts of the codebase related to the task.\n    - For example, when asked to make edits or improvements you might analyze the file structure in the initial environment_details to get an overview of the project, then use list_code_definition_names to get further insight using source code definitions for files located in relevant directories, then read_file to examine the contents of relevant files, analyze the code and suggest improvements or make necessary edits, then use the apply_diff or write_to_file tool to apply the changes. If you refactored code that could affect other parts of the codebase, you could use search_files to ensure you update other files as needed.\n- You can use the execute_command tool to run commands on the user's computer whenever you feel it can help accomplish the user's task. When you need to execute a CLI command, you must provide a clear explanation of what the command does. Prefer to execute complex CLI commands over creating executable scripts, since they are more flexible and easier to run. Interactive and long-running commands are allowed, since the commands are run in the user's VSCode terminal. The user may keep commands running in the background and you will be kept updated on their status along the way. Each command you execute is run in a new terminal instance.\n- You have access to MCP servers that may provide additional tools and resources. Each server may provide different capabilities that you can use to accomplish tasks more effectively.\n\n\n====\n\nMODES\n\n- These are the currently available modes:\n  * \"üíª Code\" mode (code) - You are Roo, a highly skilled software engineer with extensive knowledge in many programming languages, frameworks, design patterns, and best practices\n  * \"üèóÔ∏è Architect\" mode (architect) - You are Roo, an experienced technical leader who is inquisitive and an excellent planner\n  * \"‚ùì Ask\" mode (ask) - You are Roo, a knowledgeable technical assistant focused on answering questions and providing information about software development, technology, and related topics\n  * \"ü™≤ Debug\" mode (debug) - You are Roo, an expert software debugger specializing in systematic problem diagnosis and resolution\n  * \"ü™É Orchestrator\" mode (orchestrator) - You are Roo, a strategic workflow orchestrator who coordinates complex tasks by delegating them to appropriate specialized modes\nIf the user asks you to create or edit a new mode for this project, you should read the instructions by using the fetch_instructions tool, like this:\n<fetch_instructions>\n<task>create_mode</task>\n</fetch_instructions>\n\n\n====\n\nRULES\n\n- The project base directory is: c:/projects/openai-gemini-mod\n- All file paths must be relative to this directory. However, commands may change directories in terminals, so respect working directory specified by the response to <execute_command>.\n- You cannot `cd` into a different directory to complete a task. You are stuck operating from 'c:/projects/openai-gemini-mod', so be sure to pass in the correct 'path' parameter when using tools that require a path.\n- Do not use the ~ character or $HOME to refer to the home directory.\n- Before using the execute_command tool, you must first think about the SYSTEM INFORMATION context provided to understand the user's environment and tailor your commands to ensure they are compatible with their system. You must also consider if the command you need to run should be executed in a specific directory outside of the current working directory 'c:/projects/openai-gemini-mod', and if so prepend with `cd`'ing into that directory && then executing the command (as one command since you are stuck operating from 'c:/projects/openai-gemini-mod'). For example, if you needed to run `npm install` in a project outside of 'c:/projects/openai-gemini-mod', you would need to prepend with a `cd` i.e. pseudocode for this would be `cd (path to project) && (command, in this case npm install)`.\n- When using the search_files tool, craft your regex patterns carefully to balance specificity and flexibility. Based on the user's task you may use it to find code patterns, TODO comments, function definitions, or any text-based information across the project. The results include context, so analyze the surrounding code to better understand the matches. Leverage the search_files tool in combination with other tools for more comprehensive analysis. For example, use it to find specific code patterns, then use read_file to examine the full context of interesting matches before using apply_diff or write_to_file to make informed changes.\n- When creating a new project (such as an app, website, or any software project), organize all new files within a dedicated project directory unless the user specifies otherwise. Use appropriate file paths when writing files, as the write_to_file tool will automatically create any necessary directories. Structure the project logically, adhering to best practices for the specific type of project being created. Unless otherwise specified, new projects should be easily run without additional setup, for example most projects can be built in HTML, CSS, and JavaScript - which you can open in a browser.\n- For editing files, you have access to these tools: apply_diff (for replacing lines in existing files), write_to_file (for creating new files or complete file rewrites), insert_content (for adding lines to existing files), search_and_replace (for finding and replacing individual pieces of text).\n- The insert_content tool adds lines of text to files at a specific line number, such as adding a new function to a JavaScript file or inserting a new route in a Python file. Use line number 0 to append at the end of the file, or any positive number to insert before that line.\n- The search_and_replace tool finds and replaces text or regex in files. This tool allows you to search for a specific regex pattern or text and replace it with another value. Be cautious when using this tool to ensure you are replacing the correct text. It can support multiple operations at once.\n- You should always prefer using other editing tools over write_to_file when making changes to existing files since write_to_file is much slower and cannot handle large files.\n- When using the write_to_file tool to modify a file, use the tool directly with the desired content. You do not need to display the content before using the tool. ALWAYS provide the COMPLETE file content in your response. This is NON-NEGOTIABLE. Partial updates or placeholders like '// rest of code unchanged' are STRICTLY FORBIDDEN. You MUST include ALL parts of the file, even if they haven't been modified. Failure to do so will result in incomplete or broken code, severely impacting the user's project.\n- Some modes have restrictions on which files they can edit. If you attempt to edit a restricted file, the operation will be rejected with a FileRestrictionError that will specify which file patterns are allowed for the current mode.\n- Be sure to consider the type of project (e.g. Python, JavaScript, web application) when determining the appropriate structure and files to include. Also consider what files may be most relevant to accomplishing the task, for example looking at a project's manifest file would help you understand the project's dependencies, which you could incorporate into any code you write.\n  * For example, in architect mode trying to edit app.js would be rejected because architect mode can only edit files matching \"\\.md$\"\n- When making changes to code, always consider the context in which the code is being used. Ensure that your changes are compatible with the existing codebase and that they follow the project's coding standards and best practices.\n- Do not ask for more information than necessary. Use the tools provided to accomplish the user's request efficiently and effectively. When you've completed your task, you must use the attempt_completion tool to present the result to the user. The user may provide feedback, which you can use to make improvements and try again.\n- You are only allowed to ask the user questions using the ask_followup_question tool. Use this tool only when you need additional details to complete a task, and be sure to use a clear and concise question that will help you move forward with the task. When you ask a question, provide the user with 2-4 suggested answers based on your question so they don't need to do so much typing. The suggestions should be specific, actionable, and directly related to the completed task. They should be ordered by priority or logical sequence. However if you can use the available tools to avoid having to ask the user questions, you should do so. For example, if the user mentions a file that may be in an outside directory like the Desktop, you should use the list_files tool to list the files in the Desktop and check if the file they are talking about is there, rather than asking the user to provide the file path themselves.\n- When executing commands, if you don't see the expected output, assume the terminal executed the command successfully and proceed with the task. The user's terminal may be unable to stream the output back properly. If you absolutely need to see the actual terminal output, use the ask_followup_question tool to request the user to copy and paste it back to you.\n- The user may provide a file's contents directly in their message, in which case you shouldn't use the read_file tool to get the file contents again since you already have it.\n- Your goal is to try to accomplish the user's task, NOT engage in a back and forth conversation.\n- NEVER end attempt_completion result with a question or request to engage in further conversation! Formulate the end of your result in a way that is final and does not require further input from the user.\n- You are STRICTLY FORBIDDEN from starting your messages with \"Great\", \"Certainly\", \"Okay\", \"Sure\". You should NOT be conversational in your responses, but rather direct and to the point. For example you should NOT say \"Great, I've updated the CSS\" but instead something like \"I've updated the CSS\". It is important you be clear and technical in your messages.\n- When presented with images, utilize your vision capabilities to thoroughly examine them and extract meaningful information. Incorporate these insights into your thought process as you accomplish the user's task.\n- At the end of each user message, you will automatically receive environment_details. This information is not written by the user themselves, but is auto-generated to provide potentially relevant context about the project structure and environment. While this information can be valuable for understanding the project context, do not treat it as a direct part of the user's request or response. Use it to inform your actions and decisions, but don't assume the user is explicitly asking about or referring to this information unless they clearly do so in their message. When using environment_details, explain your actions clearly to ensure the user understands, as they may not be aware of these details.\n- Before executing commands, check the \"Actively Running Terminals\" section in environment_details. If present, consider how these active processes might impact your task. For example, if a local development server is already running, you wouldn't need to start it again. If no active terminals are listed, proceed with command execution as normal.\n- MCP operations should be used one at a time, similar to other tool usage. Wait for confirmation of success before proceeding with additional operations.\n- It is critical you wait for the user's response after each tool use, in order to confirm the success of the tool use. For example, if asked to make a todo app, you would create a file, wait for the user's response it was created successfully, then create another file if needed, wait for the user's response it was created successfully, etc.\n\n====\n\nSYSTEM INFORMATION\n\nOperating System: Windows 11\nDefault Shell: C:\\Program Files\\PowerShell\\7\\pwsh.exe\nHome Directory: C:/Users/vadash\nCurrent Workspace Directory: c:/projects/openai-gemini-mod\n\nThe Current Workspace Directory is the active VS Code project directory, and is therefore the default directory for all tool operations. New terminals will be created in the current workspace directory, however if you change directories in a terminal it will then have a different working directory; changing directories in a terminal does not modify the workspace directory, because you do not have access to change the workspace directory. When the user initially gives you a task, a recursive list of all filepaths in the current workspace directory ('/test/path') will be included in environment_details. This provides an overview of the project's file structure, offering key insights into the project from directory/file names (how developers conceptualize and organize their code) and file extensions (the language used). This can also guide decision-making on which files to explore further. If you need to further explore directories such as outside the current workspace directory, you can use the list_files tool. If you pass 'true' for the recursive parameter, it will list files recursively. Otherwise, it will list files at the top level, which is better suited for generic directories where you don't necessarily need the nested structure, like the Desktop.\n\n====\n\nOBJECTIVE\n\nYou accomplish a given task iteratively, breaking it down into clear steps and working through them methodically.\n\n1. Analyze the user's task and set clear, achievable goals to accomplish it. Prioritize these goals in a logical order.\n2. Work through these goals sequentially, utilizing available tools one at a time as necessary. Each goal should correspond to a distinct step in your problem-solving process. You will be informed on the work completed and what's remaining as you go.\n3. Remember, you have extensive capabilities with access to a wide range of tools that can be used in powerful and clever ways as necessary to accomplish each goal. Before calling a tool, do some analysis within <thinking></thinking> tags. First, analyze the file structure provided in environment_details to gain context and insights for proceeding effectively. Then, think about which of the provided tools is the most relevant tool to accomplish the user's task. Next, go through each of the required parameters of the relevant tool and determine if the user has directly provided or given enough information to infer a value. When deciding if the parameter can be inferred, carefully consider all the context to see if it supports a specific value. If all of the required parameters are present or can be reasonably inferred, close the thinking tag and proceed with the tool use. BUT, if one of the values for a required parameter is missing, DO NOT invoke the tool (not even with fillers for the missing params) and instead, ask the user to provide the missing parameters using the ask_followup_question tool. DO NOT ask for more information on optional parameters if it is not provided.\n4. Once you've completed the user's task, you must use the attempt_completion tool to present the result of the task to the user. You may also provide a CLI command to showcase the result of your task; this can be particularly useful for web development tasks, where you can run e.g. `open index.html` to show the website you've built.\n5. The user may provide feedback, which you can use to make improvements and try again. But DO NOT continue in pointless back and forth conversations, i.e. don't end your responses with questions or offers for further assistance.\n\n\n====\n\nUSER'S CUSTOM INSTRUCTIONS\n\nThe following additional instructions are provided by the user, and should be followed to the best of your ability without interfering with the TOOL USE guidelines.\n\nLanguage Preference:\nYou should always speak and think in the \"English\" (en) language unless the user gives you instructions below to do otherwise.\n\nMode-specific Instructions:\nYou can analyze code, explain concepts, and access external resources. Always answer the user‚Äôs questions thoroughly, and do not switch to implementing code unless explicitly requested by the user. Include Mermaid diagrams when they clarify your response."
      },
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "<task>\nHow to use supabase? Use context7\n</task>"
          },
          {
            "type": "text",
            "text": "<environment_details>\n# VSCode Visible Files\n\n\n# VSCode Open Tabs\n\n\n# Current Time\n5/30/2025, 10:59:01 PM (Europe/Istanbul, UTC+3:00)\n\n# Current Context Size (Tokens)\n(Not available)\n\n# Current Cost\n$0.00\n\n# Current Mode\n<slug>ask</slug>\n<name>‚ùì Ask</name>\n<model>gemini-2.5-flash-preview-05-20-refined-high</model>\n<role>You are Roo, a knowledgeable technical assistant focused on answering questions and providing information about software development, technology, and related topics.</role>\n<custom_instructions>\n====\n\nUSER'S CUSTOM INSTRUCTIONS\n\nThe following additional instructions are provided by the user, and should be followed to the best of your ability without interfering with the TOOL USE guidelines.\n\nLanguage Preference:\nYou should always speak and think in the \"English\" (en) language unless the user gives you instructions below to do otherwise.\n\nMode-specific Instructions:\nYou can analyze code, explain concepts, and access external resources. Always answer the user‚Äôs questions thoroughly, and do not switch to implementing code unless explicitly requested by the user. Include Mermaid diagrams when they clarify your response.</custom_instructions>\n\n\nNOTE: You are currently in '‚ùì Ask' mode, which does not allow write operations. To write files, the user will need to switch to a mode that supports file writing, such as 'üíª Code' mode.\n\n# Current Workspace Directory (c:/projects/openai-gemini-mod) Files\n\n\n(File list truncated. Use list_files on specific subdirectories if you need to explore further.)\n</environment_details>"
          }
        ]
      },
      {
        "role": "assistant",
        "content": "<use_mcp_tool>\n<server_name>Context7</server_name>\n<tool_name>resolve-library-id</tool_name>\n<arguments>\n{\n  \"libraryName\": \"Supabase\"\n}\n</arguments>\n</use_mcp_tool>"
      },
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "[use_mcp_tool for 'Context7'] Result:"
          },
          {
            "type": "text",
            "text": "Available Libraries (top matches):\n\nEach result includes:\n- Library ID: Context7-compatible identifier (format: /org/project)\n- Name: Library or package name\n- Description: Short summary\n- Code Snippets: Number of available code examples\n- Trust Score: Authority indicator\n- Versions: List of versions if available. Use one of those versions if and only if the user explicitly provides a version in their query.\n\nFor best results, select libraries based on name match, trust score, snippet coverage, and relevance to your use case.\n\n----------\n\n- Title: Supabase UI\n- Context7-compatible library ID: /supabase/ui\n- Description: Supabase UI Library\n- Code Snippets: 15\n- Trust Score: 9.5\n----------\n- Title: Supabase CLI\n- Context7-compatible library ID: /supabase/cli\n- Description: Supabase CLI. Manage postgres migrations, run Supabase locally, deploy edge functions. Postgres backups. Generating types from your database schema.\n- Code Snippets: 43\n- Trust Score: 9.5\n----------\n- Title: Supabase SSR\n- Context7-compatible library ID: /supabase/ssr\n- Description: Supabase clients for use in server-side rendering frameworks.\n- Code Snippets: 3\n- Trust Score: 9.5\n----------\n- Title: Supabase\n- Context7-compatible library ID: /supabase/supabase\n- Description: The open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.\n- Code Snippets: 4990\n- Trust Score: 9.5\n----------\n- Title: Supabase Py\n- Context7-compatible library ID: /supabase/supabase-py\n- Description: Python Client for Supabase. Query Postgres from Flask, Django, FastAPI. Python user authentication, security policies, edge functions, file storage, and realtime data streaming. Good first issue.\n- Code Snippets: 22\n- Trust Score: 9.5\n----------\n- Title: Supabase MCP\n- Context7-compatible library ID: /coleam00/supabase-mcp\n- Description: Supabase MCP server created in Python.\n- Code Snippets: 12\n- Trust Score: 8.5\n----------\n- Title: Supabase RS\n- Context7-compatible library ID: /floris-xlx/supabase_rs\n- Description: Supabase SDK for Rust\n- Code Snippets: 20\n- Trust Score: 7.4\n----------\n- Title: Supabase Go\n- Context7-compatible library ID: /antoineross/supabase-go\n- Description: A Go Client library for Supabase ‚Äî adapted to be closer to the JS SDK\n- Code Snippets: 3\n- Trust Score: 8.3\n----------\n- Title: Supabase Realtime\n- Context7-compatible library ID: /supabase/realtime\n- Description: Broadcast, Presence, and Postgres Changes via WebSockets\n- Code Snippets: 7\n- Trust Score: 9.5\n----------\n- Title: Supabase Swift\n- Context7-compatible library ID: /supabase/supabase-swift\n- Description: A Swift client for Supabase\n- Code Snippets: 88\n- Trust Score: 9.5\n----------\n- Title: Supabase Go\n- Context7-compatible library ID: /supabase-community/supabase-go\n- Description: A Go Client library for Supabase\n- Code Snippets: 3\n- Trust Score: 8.8\n----------\n- Title: Supabase KT\n- Context7-compatible library ID: /supabase-community/supabase-kt\n- Description: A Kotlin Multiplatform Client for Supabase. \n- Code Snippets: 85\n- Trust Score: 8.8\n----------\n- Title: Supabase Flutter\n- Context7-compatible library ID: /supabase/supabase-flutter\n- Description: Flutter integration for Supabase. This package makes it simple for developers to build secure and scalable products.\n- Code Snippets: 82\n- Trust Score: 9.5\n----------\n- Title: Supabase Auth Go\n- Context7-compatible library ID: /supabase-community/auth-go\n- Description: \n- Code Snippets: 6\n- Trust Score: 8.8\n----------\n- Title: Supabase MCP\n- Context7-compatible library ID: /supabase-community/supabase-mcp\n- Description: Connect Supabase to your AI assistants\n- Code Snippets: 19\n- Trust Score: 8.8\n----------\n- Title: Supabase C#\n- Context7-compatible library ID: /supabase-community/supabase-csharp\n- Description: A C# Client library for Supabase\n- Code Snippets: 3\n- Trust Score: 8.8\n----------\n- Title: Supabase Auth RS\n- Context7-compatible library ID: /supabase-community/supabase-auth-rs\n- Description: Supabase auth client implemented in rust. Currently in beta, with the goal of feature parity with the current official client libraries. https://github.com/supabase-community\n- Code Snippets: 10\n- Trust Score: 8.8\n----------\n- Title: Supabase Traefik\n- Context7-compatible library ID: /supabase-community/supabase-traefik\n- Description: \n- Code Snippets: 10\n- Trust Score: 8.8\n----------\n- Title: Supabase MCP Server\n- Context7-compatible library ID: /alexander-zuev/supabase-mcp-server\n- Description: Query MCP enables end-to-end management of Supabase via chat interface: read & write query executions, management API support, automatic migration versioning, access to logs and much more.\n- Code Snippets: 171\n- Trust Score: 8.3\n----------\n- Title: Supabase Cache Helpers\n- Context7-compatible library ID: /psteinroe/supabase-cache-helpers\n- Description: A collection of framework specific Cache utilities for working with Supabase.\n- Code Snippets: 94\n- Trust Score: 9.5\n----------\n- Title: Postgres\n- Context7-compatible library ID: /supabase/postgres\n- Description: Unmodified Postgres with some useful plugins\n- Code Snippets: 75\n- Trust Score: 9.5\n----------\n- Title: Y-Supabase\n- Context7-compatible library ID: /alexdunmow/y-supabase\n- Description: Supabase Provider for Yjs\n- Code Snippets: 4\n- Trust Score: 5.6\n----------\n- Title: Nuxt Supabase\n- Context7-compatible library ID: /nuxt-modules/supabase\n- Description: Supabase module for Nuxt.\n- Code Snippets: 41\n----------\n- Title: Postgres Meta\n- Context7-compatible library ID: /supabase/postgres-meta\n- Description: A RESTful API for managing your Postgres. Fetch tables, add roles, and run queries\n- Code Snippets: 8\n- Trust Score: 9.5\n----------\n- Title: MakerKit\n- Context7-compatible library ID: /techupbusiness/makerkit-documentation-react-router-supabase-turbo\n- Description: The source of files of the documentation on makerkit.dev\n- Code Snippets: 363\n- Trust Score: 6.3"
          },
          {
            "type": "text",
            "text": "<environment_details>\n# VSCode Visible Files\n\n\n# VSCode Open Tabs\n\n\n# Current Time\n5/30/2025, 11:02:18 PM (Europe/Istanbul, UTC+3:00)\n\n# Current Context Size (Tokens)\n8,983 (4%)\n\n# Current Cost\n$0.00\n\n# Current Mode\n<slug>ask</slug>\n<name>‚ùì Ask</name>\n<model>gemini-2.5-flash-preview-05-20-refined-high</model>\n<role>You are Roo, a knowledgeable technical assistant focused on answering questions and providing information about software development, technology, and related topics.</role>\n<custom_instructions>\n====\n\nUSER'S CUSTOM INSTRUCTIONS\n\nThe following additional instructions are provided by the user, and should be followed to the best of your ability without interfering with the TOOL USE guidelines.\n\nLanguage Preference:\nYou should always speak and think in the \"English\" (en) language unless the user gives you instructions below to do otherwise.\n\nMode-specific Instructions:\nYou can analyze code, explain concepts, and access external resources. Always answer the user‚Äôs questions thoroughly, and do not switch to implementing code unless explicitly requested by the user. Include Mermaid diagrams when they clarify your response.</custom_instructions>\n\n\nNOTE: You are currently in '‚ùì Ask' mode, which does not allow write operations. To write files, the user will need to switch to a mode that supports file writing, such as 'üíª Code' mode.\n</environment_details>"
          }
        ]
      },
      {
        "role": "assistant",
        "content": "<use_mcp_tool>\n<server_name>Context7</server_name>\n<tool_name>get-library-docs</tool_name>\n<arguments>\n{\n  \"context7CompatibleLibraryID\": \"/supabase/supabase\"\n}\n</arguments>\n</use_mcp_tool>"
      },
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "[use_mcp_tool for 'Context7'] Result:"
          },
          {
            "type": "text",
            "text": "TITLE: Creating Hugging Face Embedding Edge Function (TypeScript)\nDESCRIPTION: This Deno/TypeScript Edge Function demonstrates how to create a serverless API endpoint that accepts text input, generates embeddings using a Hugging Face model (`Supabase/gte-small` via `@xenova/transformers`), and then stores these embeddings in a Supabase database. It leverages `supabase-js` for database interaction and `deno.land/std` for serving HTTP requests.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2023-08-07-hugging-face-supabase.mdx#_snippet_3\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts'\nimport { env, pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.5.0'\nimport { createClient } from 'jsr:@supabase/supabase-js@2'\n\n// Preparation for Deno runtime\nenv.useBrowserCache = false\nenv.allowLocalModels = false\n\nconst supabase = createClient(\n  'https://xyzcompany.supabase.co',\n  'public-anon-key',\n)\n\n// Construct pipeline outside of serve for faster warm starts\nconst pipe = await pipeline(\n  'feature-extraction',\n  'Supabase/gte-small',\n)\n\n// Deno Handler\nserve(async (req) => {\n  const { input } = await req.json()\n\n  // Generate the embedding from the user input\n  const output = await pipe(input, {\n    pooling: 'mean',\n    normalize: true,\n  })\n\n  // Get the embedding output\n  const embedding = Array.from(output.data)\n\n  // Store the embedding\n  const { data, error } = await supabase\n    .from('collections')\n    .insert({ embedding })\n\n  // Return the embedding\n  return new Response(\n    { new_row: data },\n    { headers: { 'Content-Type': 'application/json' } },\n  )\n})\n```\n\n----------------------------------------\n\nTITLE: Correct: Supabase SSR Cookie Handling Pattern (TypeScript)\nDESCRIPTION: This snippet illustrates the REQUIRED and correct pattern for handling cookies when initializing Supabase clients for SSR. It mandates the use of `getAll()` and `setAll(cookiesToSet)` methods, ensuring proper session management and preventing application breakage. AI models MUST always generate this exact pattern.\nSOURCE: https://github.com/supabase/supabase/blob/master/examples/prompts/nextjs-supabase-auth.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n{\n  cookies: {\n    getAll() {\n      return cookieStore.getAll()\n    },\n    setAll(cookiesToSet) {\n      const response = NextResponse.next({\n        request,\n      })\n      \n      cookiesToSet.forEach(({ name, value, options }) => {\n        response.cookies.set(name, value, options)\n      })\n      \n      return response\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Supabase Edge Function for Hugging Face Image Captioning\nDESCRIPTION: This TypeScript Edge Function, designed for Deno, processes webhook payloads from Supabase Storage object insertions. It retrieves a signed URL for the newly uploaded image, uses the Hugging Face Inference API (`nlpconnect/vit-gpt2-image-captioning` model) to generate a caption, and then stores this caption along with the image ID in the `image_caption` table in Supabase. It requires `HUGGINGFACE_ACCESS_TOKEN`, `SUPABASE_URL`, and `SUPABASE_SERVICE_ROLE_KEY` environment variables.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/ai/examples/huggingface-image-captioning.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts'\nimport { HfInference } from 'https://esm.sh/@huggingface/inference@2.3.2'\nimport { createClient } from 'jsr:@supabase/supabase-js@2'\nimport { Database } from './types.ts'\n\nconsole.log('Hello from `huggingface-image-captioning` function!')\n\nconst hf = new HfInference(Deno.env.get('HUGGINGFACE_ACCESS_TOKEN'))\n\ntype SoRecord = Database['storage']['Tables']['objects']['Row']\ninterface WebhookPayload {\n  type: 'INSERT' | 'UPDATE' | 'DELETE'\n  table: string\n  record: SoRecord\n  schema: 'public'\n  old_record: null | SoRecord\n}\n\nserve(async (req) => {\n  const payload: WebhookPayload = await req.json()\n  const soRecord = payload.record\n  const supabaseAdminClient = createClient<Database>(\n    // Supabase API URL - env var exported by default when deployed.\n    Deno.env.get('SUPABASE_URL') ?? '',\n    // Supabase API SERVICE ROLE KEY - env var exported by default when deployed.\n    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''\n  )\n\n  // Construct image url from storage\n  const { data, error } = await supabaseAdminClient.storage\n    .from(soRecord.bucket_id!)\n    .createSignedUrl(soRecord.path_tokens!.join('/'), 60)\n  if (error) throw error\n  const { signedUrl } = data\n\n  // Run image captioning with Huggingface\n  const imgDesc = await hf.imageToText({\n    data: await (await fetch(signedUrl)).blob(),\n    model: 'nlpconnect/vit-gpt2-image-captioning',\n  })\n\n  // Store image caption in Database table\n  await supabaseAdminClient\n    .from('image_caption')\n    .insert({ id: soRecord.id!, caption: imgDesc.generated_text })\n    .throwOnError()\n\n  return new Response('ok')\n})\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client - JavaScript\nDESCRIPTION: Initializes the Supabase client in JavaScript using the provided project URL and anonymous public API key. This client instance is used for all subsequent Supabase interactions.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/realtime/broadcast.mdx#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js'\n\nconst SUPABASE_URL = 'https://<project>.supabase.co'\nconst SUPABASE_KEY = '<your-anon-key>'\n\nconst supabase = createClient(SUPABASE_URL, SUPABASE_KEY)\n```\n\n----------------------------------------\n\nTITLE: Implementing TOTP MFA Enrollment in React\nDESCRIPTION: This React component, `EnrollMFA`, facilitates the TOTP MFA enrollment process. It initiates enrollment by calling `supabase.auth.mfa.enroll()` to retrieve a QR code and factor ID. The QR code is then displayed for the user to scan with their authenticator app. Once the user enters a verification code, the component uses `supabase.auth.mfa.challenge()` and `supabase.auth.mfa.verify()` to validate the code and activate the MFA factor, handling errors and providing callbacks for completion or cancellation.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/auth/auth-mfa/totp.mdx#_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n/**\n * EnrollMFA shows a simple enrollment dialog. When shown on screen it calls\n * the `enroll` API. Each time a user clicks the Enable button it calls the\n * `challenge` and `verify` APIs to check if the code provided by the user is\n * valid.\n * When enrollment is successful, it calls `onEnrolled`. When the user clicks\n * Cancel the `onCancelled` callback is called.\n */\nexport function EnrollMFA({\n  onEnrolled,\n  onCancelled,\n}: {\n  onEnrolled: () => void\n  onCancelled: () => void\n}) {\n  const [factorId, setFactorId] = useState('')\n  const [qr, setQR] = useState('') // holds the QR code image SVG\n  const [verifyCode, setVerifyCode] = useState('') // contains the code entered by the user\n  const [error, setError] = useState('') // holds an error message\n\n  const onEnableClicked = () => {\n    setError('')\n    ;(async () => {\n      const challenge = await supabase.auth.mfa.challenge({ factorId })\n      if (challenge.error) {\n        setError(challenge.error.message)\n        throw challenge.error\n      }\n\n      const challengeId = challenge.data.id\n\n      const verify = await supabase.auth.mfa.verify({\n        factorId,\n        challengeId,\n        code: verifyCode,\n      })\n      if (verify.error) {\n        setError(verify.error.message)\n        throw verify.error\n      }\n\n      onEnrolled()\n    })()\n  }\n\n  useEffect(() => {\n    ;(async () => {\n      const { data, error } = await supabase.auth.mfa.enroll({\n        factorType: 'totp',\n      })\n      if (error) {\n        throw error\n      }\n\n      setFactorId(data.id)\n\n      // Supabase Auth returns an SVG QR code which you can convert into a data\n      // URL that you can place in an <img> tag.\n      setQR(data.totp.qr_code)\n    })()\n  }, [])\n\n  return (\n    <>\n      {error && <div className=\"error\">{error}</div>}\n      <img src={qr} />\n      <input\n        type=\"text\"\n        value={verifyCode}\n        onChange={(e) => setVerifyCode(e.target.value.trim())}\n      />\n      <input type=\"button\" value=\"Enable\" onClick={onEnableClicked} />\n      <input type=\"button\" value=\"Cancel\" onClick={onCancelled} />\n    </>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Scheduling Edge Function Invocation with pg_cron and pg_net (SQL)\nDESCRIPTION: This SQL snippet uses the `pg_cron` extension to schedule a recurring task that invokes a Supabase Edge Function every minute. It leverages `pg_net` to perform an HTTP POST request, dynamically retrieving the project URL and anonymous key from `vault.decrypted_secrets` for authentication, and sends a JSON body containing the current timestamp.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/functions/schedule-functions.mdx#_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nselect\n  cron.schedule(\n    'invoke-function-every-minute',\n    '* * * * *', -- every minute\n    $$\n    select\n      net.http_post(\n          url:= (select decrypted_secret from vault.decrypted_secrets where name = 'project_url') || '/functions/v1/function-name',\n          headers:=jsonb_build_object(\n            'Content-type', 'application/json',\n            'Authorization', 'Bearer ' || (select decrypted_secret from vault.decrypted_secrets where name = 'anon_key')\n          ),\n          body:=concat('{\"time\": \"', now(), '\"}')::jsonb\n      ) as request_id;\n    $$\n  );\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client in TypeScript\nDESCRIPTION: This TypeScript snippet demonstrates how to create and export a Supabase client instance using the `createClient` function from `@supabase/supabase-js`. It retrieves the Supabase URL and `anon` key from environment variables, enabling the application to interact with Supabase services like authentication and database operations.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/getting-started/tutorials/with-ionic-vue.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL as string;\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY as string;\n\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey);\n```\n\n----------------------------------------\n\nTITLE: Declaring Supabase Environment Variables (.env.local)\nDESCRIPTION: This snippet shows the required environment variables for connecting a Next.js application to Supabase. Users must rename `.env.example` to `.env.local` and replace the placeholders with their actual Supabase URL and anonymous key, which are crucial for API communication.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/getting-started/quickstarts/nextjs.mdx#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nNEXT_PUBLIC_SUPABASE_URL=<SUBSTITUTE_SUPABASE_URL>\nNEXT_PUBLIC_SUPABASE_ANON_KEY=<SUBSTITUTE_SUPABASE_ANON_KEY>\n```\n\n----------------------------------------\n\nTITLE: Configuring Supabase Client with Environment Variables (TypeScript)\nDESCRIPTION: This TypeScript snippet defines and exports `supabaseClient` by initializing it with `createClient` from `@refinedev/supabase`. It retrieves the Supabase URL and anonymous key from Vite environment variables (`VITE_SUPABASE_URL`, `VITE_SUPABASE_ANON_KEY`) and configures the client to use the 'public' schema and persist user sessions. This client is central for all Supabase interactions within the Refine app.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/getting-started/tutorials/with-refine.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createClient } from '@refinedev/supabase'\n\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY\n\nexport const supabaseClient = createClient(supabaseUrl, supabaseAnonKey, {\n  db: {\n    schema: 'public',\n  },\n  auth: {\n    persistSession: true,\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client with Service Role Key (TypeScript)\nDESCRIPTION: This snippet demonstrates how to create a Supabase client instance specifically for server-side operations using the `service_role` secret. It imports `createClient` from `@supabase/supabase-js` and configures the `auth` object to disable session persistence, auto-refresh, and URL session detection, which are crucial for secure server environments to prevent accidental exposure of the secret.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/troubleshooting/performing-administration-tasks-on-the-server-side-with-the-servicerole-secret-BYM4Fa.mdx#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js'\n\nconst supabase = createClient(supabaseUrl, serviceRoleSecret, {\n  auth: {\n    persistSession: false,\n    autoRefreshToken: false,\n    detectSessionInUrl: false,\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Creating a Public SELECT Policy for Profiles Table\nDESCRIPTION: This sequence of SQL commands first creates a `profiles` table, then enables Row Level Security on it. Finally, it defines a `SELECT` policy that makes all profiles visible to everyone, including unauthenticated users, by granting access to the `anon` role with a `true` condition.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/database/postgres/row-level-security.mdx#_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table profiles (\n  id uuid primary key,\n  user_id references auth.users,\n  avatar_url text\n);\n\nalter table profiles enable row level security;\n\ncreate policy \"Public profiles are visible to everyone.\"\non profiles for select\nto anon         -- the Postgres Role (recommended)\nusing ( true ); -- the actual Policy\n```\n\n----------------------------------------\n\nTITLE: Computing Routes with Google Maps API in a Supabase Edge Function\nDESCRIPTION: This TypeScript Deno function serves as an Edge Function to compute routes between an origin and destination using the Google Maps Directions API. It handles incoming JSON requests, makes a POST request to the Google API, and returns the route details, including duration, distance, and polyline.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2024-09-05-flutter-uber-clone.mdx#_snippet_11\n\nLANGUAGE: TypeScript\nCODE:\n```\ntype Coordinates = {\n  latitude: number\n  longitude: number\n}\n\nDeno.serve(async (req) => {\n  const {\n    origin,\n    destination,\n  }: {\n    origin: Coordinates\n    destination: Coordinates\n  } = await req.json()\n\n  const response = await fetch(\n    `https://routes.googleapis.com/directions/v2:computeRoutes?key=${Deno.env.get(\n      'GOOGLE_MAPS_API_KEY'\n    )}`,\n    {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'X-Goog-FieldMask':\n          'routes.duration,routes.distanceMeters,routes.polyline,routes.legs.polyline',\n      },\n      body: JSON.stringify({\n        origin: { location: { latLng: origin } },\n        destination: { location: { latLng: destination } },\n        travelMode: 'DRIVE',\n        polylineEncoding: 'GEO_JSON_LINESTRING',\n      }),\n    }\n  )\n\n  if (!response.ok) {\n    const error = await response.json()\n    console.error({ error })\n    throw new Error(`HTTP error! status: ${response.status}`)\n  }\n\n  const data = await response.json()\n\n  const res = data.routes[0]\n\n  return new Response(JSON.stringify(res), { headers: { 'Content-Type': 'application/json' } })\n})\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client in JavaScript\nDESCRIPTION: This code initializes the Supabase client using the `createClient` method. It requires the Supabase project URL and the anonymous (anon) public key, which are obtained from the Supabase dashboard's API settings. This client instance is then used for all database interactions.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2021-03-11-using-supabase-replit.mdx#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst supabase = createClient(\n  'https://ajsstlnzcmdmzbtcgbbd.supabase.co',\n  'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...'\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client\nDESCRIPTION: This section demonstrates how to initialize the Supabase client using your project's URL and anonymous public API key. These credentials can be found in your Supabase project's API Settings.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/realtime/presence.mdx#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js'\n\nconst SUPABASE_URL = 'https://<project>.supabase.co'\nconst SUPABASE_KEY = '<your-anon-key>'\n\nconst supabase = createClient(SUPABASE_URL, SUPABASE_KEY)\n```\n\nLANGUAGE: Dart\nCODE:\n```\nvoid main() {\n  Supabase.initialize(\n    url: 'https://<project>.supabase.co',\n    anonKey: '<your-anon-key>',\n  );\n\n  runApp(MyApp());\n}\n\nfinal supabase = Supabase.instance.client;\n```\n\nLANGUAGE: Swift\nCODE:\n```\nlet supabaseURL = \"https://<project>.supabase.co\"\nlet supabaseKey = \"<your-anon-key>\"\nlet supabase = SupabaseClient(supabaseURL: URL(string: supabaseURL)!, supabaseKey: supabaseKey)\n\nlet realtime = supabase.realtime\n```\n\nLANGUAGE: Kotlin\nCODE:\n```\nval supabaseUrl = \"https://<project>.supabase.co\"\nval supabaseKey = \"<your-anon-key>\"\nval supabase = createSupabaseClient(supabaseUrl, supabaseKey) {\n    install(Realtime)\n}\n```\n\nLANGUAGE: Python\nCODE:\n```\nfrom supabase import create_client\n\nSUPABASE_URL = 'https://<project>.supabase.co'\nSUPABASE_KEY = '<your-anon-key>'\n\nsupabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n```\n\n----------------------------------------\n\nTITLE: Implementing a PostgreSQL Function as a Trigger for `updated_at`\nDESCRIPTION: This example provides a PostgreSQL function `update_updated_at` designed to be used as a trigger. It automatically updates the `updated_at` column of a row to the current timestamp (`now()`) whenever the row is modified. The accompanying `CREATE TRIGGER` statement attaches this function to the `my_schema.my_table` for `BEFORE UPDATE` events.\nSOURCE: https://github.com/supabase/supabase/blob/master/examples/prompts/database-functions.md#_snippet_2\n\nLANGUAGE: PostgreSQL\nCODE:\n```\ncreate or replace function my_schema.update_updated_at()\nreturns trigger\nlanguage plpgsql\nsecurity invoker\nset search_path = ''\nas $$\nbegin\n  -- Update the \"updated_at\" column on row modification\n  new.updated_at := now();\n  return new;\nend;\n$$;\n\ncreate trigger update_updated_at_trigger\nbefore update on my_schema.my_table\nfor each row\nexecute function my_schema.update_updated_at();\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Postgres Database Changes with Supabase Realtime (JavaScript)\nDESCRIPTION: This example demonstrates how to subscribe to real-time changes from a Postgres database using Supabase Realtime. Clients can listen for specific events (e.g., INSERT, UPDATE, DELETE, or all '*') within a schema or table. Row Level Security (RLS) is crucial for controlling which changes clients are authorized to receive.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/realtime/concepts.mdx#_snippet_3\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js'\nconst supabase = createClient('your_project_url', 'your_supabase_api_key')\n\nconst allChanges = supabase\n  .channel('schema-db-changes')\n  .on(\n    'postgres_changes',\n    {\n      event: '*',\n      schema: 'public'\n    },\n    (payload) => console.log(payload)\n  )\n  .subscribe()\n```\n\n----------------------------------------\n\nTITLE: Initiating Supabase User Signup in JavaScript\nDESCRIPTION: This JavaScript snippet demonstrates how to sign up a new user with Supabase using `supabase.auth.signUp()`. It requires an email and password, and optionally allows specifying an `emailRedirectTo` URL for post-confirmation redirection, which must be configured in the Supabase dashboard or CLI.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/auth/passwords.mdx#_snippet_11\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { createClient } from '@supabase/supabase-js'\nconst supabase = createClient('https://your-project.supabase.co', 'your-anon-key')\n\n// ---cut---\nasync function signUpNewUser() {\n  const { data, error } = await supabase.auth.signUp({\n    email: 'valid.email@supabase.io',\n    password: 'example-password',\n    options: {\n      emailRedirectTo: 'https://example.com/welcome',\n    },\n  })\n}\n```\n\n----------------------------------------\n\nTITLE: Analyzing Query Execution Plans with EXPLAIN ANALYZE (SQL)\nDESCRIPTION: This SQL command is used to analyze the execution plan of a given query. When `ANALYZE` is included, the query is actually executed, providing detailed runtime statistics. It's crucial for optimizing slow queries but should be used cautiously with DML statements (INSERT/UPDATE/DELETE) due to side effects. Omitting `ANALYZE` provides a plan without execution.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/database/inspect.mdx#_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nexplain analyze <query-statement-here>;\n```\n\n----------------------------------------\n\nTITLE: Initializing Supabase Client with Encrypted Session Storage\nDESCRIPTION: This TypeScript code defines a `LargeSecureStore` class that implements encrypted session storage for Supabase in React Native. It uses `expo-secure-store` for small encryption keys and `AsyncStorage` for the larger encrypted session data, leveraging `aes-js` for AES-256 encryption. The Supabase client is then initialized to use this custom storage, enhancing the security of user sessions.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2023-11-16-react-native-authentication.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport 'react-native-url-polyfill/auto'\nimport { createClient } from '@supabase/supabase-js'\nimport AsyncStorage from '@react-native-async-storage/async-storage'\nimport * as SecureStore from 'expo-secure-store'\nimport * as aesjs from 'aes-js'\nimport 'react-native-get-random-values'\n\n// As Expo's SecureStore does not support values larger than 2048\n// bytes, an AES-256 key is generated and stored in SecureStore, while\n// it is used to encrypt/decrypt values stored in AsyncStorage.\nclass LargeSecureStore {\n  private async _encrypt(key: string, value: string) {\n    const encryptionKey = crypto.getRandomValues(new Uint8Array(256 / 8))\n\n    const cipher = new aesjs.ModeOfOperation.ctr(encryptionKey, new aesjs.Counter(1))\n    const encryptedBytes = cipher.encrypt(aesjs.utils.utf8.toBytes(value))\n\n    await SecureStore.setItemAsync(key, aesjs.utils.hex.fromBytes(encryptionKey))\n\n    return aesjs.utils.hex.fromBytes(encryptedBytes)\n  }\n\n  private async _decrypt(key: string, value: string) {\n    const encryptionKeyHex = await SecureStore.getItemAsync(key)\n    if (!encryptionKeyHex) {\n      return encryptionKeyHex\n    }\n\n    const cipher = new aesjs.ModeOfOperation.ctr(\n      aesjs.utils.hex.toBytes(encryptionKeyHex),\n      new aesjs.Counter(1)\n    )\n    const decryptedBytes = cipher.decrypt(aesjs.utils.hex.toBytes(value))\n\n    return aesjs.utils.utf8.fromBytes(decryptedBytes)\n  }\n\n  async getItem(key: string) {\n    const encrypted = await AsyncStorage.getItem(key)\n    if (!encrypted) {\n      return encrypted\n    }\n\n    return await this._decrypt(key, encrypted)\n  }\n\n  async removeItem(key: string) {\n    await AsyncStorage.removeItem(key)\n    await SecureStore.deleteItemAsync(key)\n  }\n\n  async setItem(key: string, value: string) {\n    const encrypted = await this._encrypt(key, value)\n\n    await AsyncStorage.setItem(key, encrypted)\n  }\n}\n\nconst supabaseUrl = YOUR_REACT_NATIVE_SUPABASE_URL\nconst supabaseAnonKey = YOUR_REACT_NATIVE_SUPABASE_ANON_KEY\n\nconst supabase = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    storage: new LargeSecureStore(),\n    autoRefreshToken: true,\n    persistSession: true,\n    detectSessionInUrl: false,\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Explaining a Query Plan (SQL)\nDESCRIPTION: This command is used to display the execution plan for a given SQL query. It helps developers understand how Postgres will execute the query, including which indexes are used, join methods, and scan types, which is crucial for performance tuning and debugging.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4.mdx#_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nEXPLAIN <your query>\n```\n\n----------------------------------------\n\nTITLE: Implementing Generative Search Interface with Supabase Edge Functions (JavaScript)\nDESCRIPTION: This JavaScript function `onSubmit` handles a user's search query by sending it to a Supabase Edge Function via `EventSource`. It streams the AI-generated answer back, appending it to `answer.value` until a `[DONE]` signal is received. The function manages loading states and error handling, demonstrating a headless integration for generative Q&A.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/ai/examples/headless-vector-search.mdx#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst onSubmit = (e: Event) => {\n  e.preventDefault()\n  answer.value = \"\"\n  isLoading.value = true\n\n  const query = new URLSearchParams({ query: inputRef.current!.value })\n  const projectUrl = `https://your-project-ref.supabase.co/functions/v1`\n  const queryURL = `${projectUrl}/${query}`\n  const eventSource = new EventSource(queryURL)\n\n  eventSource.addEventListener(\"error\", (err) => {\n    isLoading.value = false\n    console.error(err)\n  })\n\n  eventSource.addEventListener(\"message\", (e: MessageEvent) => {\n    isLoading.value = false\n\n    if (e.data === \"[DONE]\") {\n      eventSource.close()\n      return\n    }\n\n    const completionResponse: CreateCompletionResponse = JSON.parse(e.data)\n    const text = completionResponse.choices[0].text\n\n    answer.value += text\n  });\n\n  isLoading.value = true\n}\n```\n\n----------------------------------------\n\nTITLE: Creating User Profiles Table and Enabling RLS - Supabase SQL\nDESCRIPTION: This snippet defines the 'profiles' table to store public user information, linked to 'auth.users'. It includes constraints for username length and then enables Row Level Security (RLS) on the table, which is crucial for fine-grained access control.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/_partials/user_management_quickstart_sql_template.mdx#_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table profiles (\n  id uuid references auth.users not null primary key,\n  updated_at timestamp with time zone,\n  username text unique,\n  full_name text,\n  avatar_url text,\n  website text,\n\n  constraint username_length check (char_length(username) >= 3)\n);\nalter table profiles\n  enable row level security;\n```\n\n----------------------------------------\n\nTITLE: Svelte Authentication Component with Magic Link\nDESCRIPTION: This Svelte component (`src/lib/Auth.svelte`) handles user login and sign-up using Supabase's Magic Link authentication. It includes a form for email input, displays loading states, and provides user feedback via alerts. It depends on the `supabaseClient.ts` for Supabase interaction.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/getting-started/tutorials/with-svelte.mdx#_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<script lang=\"ts\">\n  import { supabase } from '../supabaseClient'\n\n  let loading = false\n  let email = ''\n\n  const handleLogin = async () => {\n    try {\n      loading = true\n      const { error } = await supabase.auth.signInWithOtp({ email })\n      if (error) throw error\n      alert('Check your email for login link!')\n    } catch (error) {\n      if (error instanceof Error) {\n        alert(error.message)\n      }\n    } finally {\n      loading = false\n    }\n  }\n</script>\n\n<div class=\"row flex-center flex\">\n  <div class=\"col-6 form-widget\" aria-live=\"polite\">\n    <h1 class=\"header\">Supabase + Svelte</h1>\n    <p class=\"description\">Sign in via magic link with your email below</p>\n    <\form class=\"form-widget\" on:submit|preventDefault=\"{handleLogin}\">\n      <div>\n        <label for=\"email\">Email</label>\n        <input\n          id=\"email\"\n          class=\"inputField\"\n          type=\"email\"\n          placeholder=\"Your email\"\n          bind:value=\"{email}\"\n        />\n      </div>\n      <div>\n        <\button type=\"submit\" class=\"button block\" aria-live=\"polite\" disabled=\"{loading}\">\n          <span>{loading ? 'Loading' : 'Send magic link'}</span>\n        </\button>\n      </div>\n    </\form>\n  </div>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Configuring RLS Policy with Custom Session Variable - SQL\nDESCRIPTION: This SQL snippet enables Row Level Security (RLS) on the `document_sections` table and defines a policy allowing authenticated users to select only their own document sections. It uses a custom session variable, `app.current_user_id`, to identify the current user, casting it to `bigint` for comparison with `owner_id`.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/ai/rag-with-permissions.mdx#_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\n-- enable row level security\nalter table document_sections enable row level security;\n\n-- setup RLS for select operations\ncreate policy \"Users can query their own document sections\"\non document_sections for select to authenticated using (\n  document_id in (\n    select id\n    from external.documents\n    where owner_id = current_setting('app.current_user_id')::bigint\n  )\n);\n```\n\n----------------------------------------\n\nTITLE: Authenticated OpenAI Realtime API WebSocket Relay - JavaScript\nDESCRIPTION: This snippet demonstrates how to build an authenticated WebSocket relay using Supabase Edge Functions to connect client-side applications to OpenAI's Realtime API. It handles WebSocket upgrades, authenticates users via a JWT provided in the URL query parameters using `supabase.auth.getUser`, and then establishes an outbound WebSocket connection to OpenAI. Messages are relayed between the client and OpenAI, protecting the OpenAI API key and ensuring only authenticated users can access the service.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2024-12-03-edge-functions-background-tasks-websockets.mdx#_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { createClient } from 'jsr:@supabase/supabase-js@2'\n\nconst supabase = createClient(\n  Deno.env.get('SUPABASE_URL'),\n  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')\n)\nconst OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY')\n\nDeno.serve(async (req) => {\n  const upgrade = req.headers.get('upgrade') || ''\n\n  if (upgrade.toLowerCase() != 'websocket') {\n    return new Response(\"request isn't trying to upgrade to websocket.\")\n  }\n\n  // WebSocket browser clients does not support sending custom headers.\n  // We have to use the URL query params to provide user's JWT.\n  // Please be aware query params may be logged in some logging systems.\n  const url = new URL(req.url)\n  const jwt = url.searchParams.get('jwt')\n  if (!jwt) {\n    console.error('Auth token not provided')\n    return new Response('Auth token not provided', { status: 403 })\n  }\n  const { error, data } = await supabase.auth.getUser(jwt)\n  if (error) {\n    console.error(error)\n    return new Response('Invalid token provided', { status: 403 })\n  }\n  if (!data.user) {\n    console.error('user is not authenticated')\n    return new Response('User is not authenticated', { status: 403 })\n  }\n\n  const { socket, response } = Deno.upgradeWebSocket(req)\n\n  socket.onopen = () => {\n    // initiate an outbound WebSocket connection to OpenAI\n    const url = 'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01'\n\n    // openai-insecure-api-key isn't a problem since this code runs in an Edge Function\n    const openaiWS = new WebSocket(url, [\n      'realtime',\n      `openai-insecure-api-key.${OPENAI_API_KEY}`,\n      'openai-beta.realtime-v1',\n    ])\n\n    openaiWS.onopen = () => {\n      console.log('Connected to OpenAI server.')\n\n      socket.onmessage = (e) => {\n        console.log('socket message:', e.data)\n        // only send the message if openAI ws is open\n        if (openaiWS.readyState === 1) {\n          openaiWS.send(e.data)\n        } else {\n          socket.send(\n            JSON.stringify({\n              type: 'error',\n              msg: 'openAI connection not ready',\n            })\n          )\n        }\n      }\n    }\n\n    openaiWS.onmessage = (e) => {\n      console.log(e.data)\n      socket.send(e.data)\n    }\n\n    openaiWS.onerror = (e) => console.log('OpenAI error: ', e.message)\n    openaiWS.onclose = (e) => console.log('OpenAI session closed')\n  }\n\n  socket.onerror = (e) => console.log('socket errored:', e.message)\n  socket.onclose = () => console.log('socket closed')\n\n  return response // 101 (Switching Protocols)\n})\n```\n\n----------------------------------------\n\nTITLE: Creating an UPDATE Policy for User-Owned Profiles\nDESCRIPTION: This example demonstrates creating an `UPDATE` policy for the `profiles` table. It allows authenticated users to update only their own profile, using both `using` (for existing rows) and `with check` (for new row data) clauses to ensure the `user_id` remains consistent with the authenticated user's ID.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/database/postgres/row-level-security.mdx#_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table profiles (\n  id uuid primary key,\n  user_id uuid references auth.users,\n  avatar_url text\n);\n\nalter table profiles enable row level security;\n\ncreate policy \"Users can update their own profile.\"\non profiles for update\nto authenticated                    -- the Postgres Role (recommended)\nusing ( (select auth.uid()) = user_id )       -- checks if the existing row complies with the policy expression\nwith check ( (select auth.uid()) = user_id ); -- checks if the new row complies with the policy expression\n```\n\n----------------------------------------\n\nTITLE: Creating RLS Policy for Post Owners (SQL)\nDESCRIPTION: This SQL snippet demonstrates how to create a Row Level Security (RLS) policy on the 'posts' table. The policy, named 'Allow update for owners', restricts UPDATE operations so that only the user whose 'user_id' matches the authenticated user's UID (retrieved via 'auth.uid()') can modify a row. This ensures that users can only update their own posts.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/database/postgres/column-level-security.mdx#_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\ncreate policy \"Allow update for owners\" on posts for\nupdate\n  using ((select auth.uid()) = user_id);\n```\n\n----------------------------------------\n\nTITLE: Creating 'instruments' Table and Inserting Sample Data (SQL)\nDESCRIPTION: This SQL snippet creates an 'instruments' table with 'id' and 'name' columns, inserts three sample instrument names ('violin', 'viola', 'cello'), and enables Row Level Security (RLS) on the table. It is designed to be run in the Supabase SQL Editor to quickly set up a basic table for testing.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/_partials/quickstart_db_setup.mdx#_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\n-- Create the table\ncreate table instruments (\n  id bigint primary key generated always as identity,\n  name text not null\n);\n-- Insert some sample data into the table\ninsert into instruments (name)\nvalues\n  ('violin'),\n  ('viola'),\n  ('cello');\n\nalter table instruments enable row level security;\n```\n\n----------------------------------------\n\nTITLE: Creating an INSERT Policy for User-Owned Profiles\nDESCRIPTION: This SQL block sets up a `profiles` table, enables RLS, and then defines an `INSERT` policy. The policy ensures that only authenticated users can create a profile, and that the `user_id` they attempt to insert matches their own authenticated user ID, preventing unauthorized profile creation.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/database/postgres/row-level-security.mdx#_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\ncreate table profiles (\n  id uuid primary key,\n  user_id uuid references auth.users,\n  avatar_url text\n);\n\nalter table profiles enable row level security;\n\ncreate policy \"Users can create a profile.\"\non profiles for insert\nto authenticated                          -- the Postgres Role (recommended)\nwith check ( (select auth.uid()) = user_id );      -- the actual Policy\n```\n\n----------------------------------------\n\nTITLE: Enabling the pgvector Extension in Supabase (SQL)\nDESCRIPTION: This SQL command ensures that the `pgvector` extension is enabled within the current database schema, specifically within the `extensions` schema. This is a prerequisite for utilizing any of the pgvector functionalities, including vector types and distance operators, in a Supabase project.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2024-05-01-pgvector-0-7-0.mdx#_snippet_10\n\nLANGUAGE: SQL\nCODE:\n```\ncreate extension if not exists vector\nwith\n  schema extensions;\n```\n\n----------------------------------------\n\nTITLE: Fetching Data Client-Side with React Query in Next.js Client Components\nDESCRIPTION: This snippet demonstrates a standard client-side data fetching approach using `useQuery` from `@supabase-cache-helpers/postgrest-react-query` within a Next.js Client Component. It checks if data was pre-fetched server-side; if not, it proceeds to fetch the data client-side using the browser Supabase client. The component includes basic loading and error handling states for a robust user experience.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2024-01-12-react-query-nextjs-app-router-cache-helpers.mdx#_snippet_11\n\nLANGUAGE: tsx\nCODE:\n```\n'use client'\n\nimport useSupabaseBrowser from '@/utils/supabase-browser'\nimport { getCountryById } from '@/queries/get-country-by-id'\nimport { useQuery } from '@supabase-cache-helpers/postgrest-react-query'\n\nexport default function CountryPage({ params }: { params: { id: number } }) {\n  const supabase = useSupabaseBrowser()\n  const { data: country, isLoading, isError } = useQuery(getCountryById(supabase, params.id))\n\n  if (isLoading) {\n    return <div>Loading...</div>\n  }\n\n  if (isError || !country) {\n    return <div>Error</div>\n  }\n\n  return (\n    <div>\n      <h1>{country.name}</h1>\n    </div>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Server Supabase Client for Server Components\nDESCRIPTION: Provides a function `useSupabaseServer` to create a server-side Supabase client using `@supabase/ssr`'s `createServerClient`. This client is designed for use in Next.js server components and handles cookie management for authentication, ensuring secure and authenticated data fetching on the server.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/www/_blog/2024-01-12-react-query-nextjs-app-router-cache-helpers.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createServerClient } from '@supabase/ssr'\nimport { cookies } from 'next/headers'\nimport { Database } from './database.types'\n\nexport default function useSupabaseServer(cookieStore: ReturnType<typeof cookies>) {\n  return createServerClient<Database>(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n    {\n      cookies: {\n        get(name: string) {\n          return cookieStore.get(name)?.value\n        }\n      }\n    }\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Signing In with Email and Password - Dart\nDESCRIPTION: This snippet shows how to authenticate a user in Dart by calling `signInWithPassword()` on the Supabase client. It asynchronously signs in with the provided email and password, returning an `AuthResponse`.\nSOURCE: https://github.com/supabase/supabase/blob/master/apps/docs/content/guides/auth/passwords.mdx#_snippet_17\n\nLANGUAGE: Dart\nCODE:\n```\nFuture<void> signInWithEmail() async {\n  final AuthResponse res = await supabase.auth.signInWithPassword(\n    email: 'valid.email@supabase.io',\n    password: 'example-password'\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Defining User Profiles Table with Row Level Security Policies\nDESCRIPTION: This SQL snippet defines the 'profiles' table for public user profiles, including fields for ID, update timestamp, username, avatar URL, and website. It establishes robust Row Level Security (RLS) policies to control access: public viewing, user-specific insertion, and user-specific updates. Additionally, it configures Supabase Realtime for the 'profiles' table and sets up a 'avatars' storage bucket with policies for public access and user uploads.\nSOURCE: https://github.com/supabase/supabase/blob/master/examples/user-management/react-user-management/README.md#_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- Create a table for Public Profiles\ncreate table\n  profiles (\n    id uuid references auth.users not null,\n    updated_at timestamp\n    with\n      time zone,\n      username text unique,\n      avatar_url text,\n      website text,\n      primary key (id),\n      unique (username),\n      constraint username_length check (char_length(username) >= 3)\n  );\n\nalter table\n  profiles enable row level security;\n\ncreate policy \"Public profiles are viewable by everyone.\" on profiles for\nselect\n  using (true);\n\ncreate policy \"Users can insert their own profile.\" on profiles for insert\nwith\n  check ((select auth.uid()) = id);\n\ncreate policy \"Users can update own profile.\" on profiles for\nupdate\n  using ((select auth.uid()) = id);\n\n-- Set up Realtime!\nbegin;\n\ndrop\n  publication if exists supabase_realtime;\n\ncreate publication supabase_realtime;\n\ncommit;\n\nalter\n  publication supabase_realtime add table profiles;\n\n-- Set up Storage!\ninsert into\n  storage.buckets (id, name)\nvalues\n  ('avatars', 'avatars');\n\ncreate policy \"Avatar images are publicly accessible.\" on storage.objects for\nselect\n  using (bucket_id = 'avatars');\n\ncreate policy \"Anyone can upload an avatar.\" on storage.objects for insert\nwith\n  check (bucket_id = 'avatars');\n```"
          },
          {
            "type": "text",
            "text": "<environment_details>\n# VSCode Visible Files\n\n\n# VSCode Open Tabs\n\n\n# Current Time\n5/30/2025, 11:03:44 PM (Europe/Istanbul, UTC+3:00)\n\n# Current Context Size (Tokens)\n11,055 (6%)\n\n# Current Cost\n$0.00\n\n# Current Mode\n<slug>ask</slug>\n<name>‚ùì Ask</name>\n<model>gemini-2.5-flash-preview-05-20-refined-high</model>\n<role>You are Roo, a knowledgeable technical assistant focused on answering questions and providing information about software development, technology, and related topics.</role>\n<custom_instructions>\n====\n\nUSER'S CUSTOM INSTRUCTIONS\n\nThe following additional instructions are provided by the user, and should be followed to the best of your ability without interfering with the TOOL USE guidelines.\n\nLanguage Preference:\nYou should always speak and think in the \"English\" (en) language unless the user gives you instructions below to do otherwise.\n\nMode-specific Instructions:\nYou can analyze code, explain concepts, and access external resources. Always answer the user‚Äôs questions thoroughly, and do not switch to implementing code unless explicitly requested by the user. Include Mermaid diagrams when they clarify your response.</custom_instructions>\n\n\nNOTE: You are currently in '‚ùì Ask' mode, which does not allow write operations. To write files, the user will need to switch to a mode that supports file writing, such as 'üíª Code' mode.\n</environment_details>"
          }
        ]
      }
    ],
    "stream": true,
    "stream_options": {
      "include_usage": true
    }
  }