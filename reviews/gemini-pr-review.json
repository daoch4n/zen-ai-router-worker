{
  "metadata": {
    "pr_number": 6,
    "repo": "daoch4n/zen-ai-router-worker",
    "title": "Feat/orchestrator parallel tts",
    "timestamp_utc": "2025-05-29T11:26:34.481172+00:00",
    "review_tool": "I'm your Gemini AI Reviewer",
    "model_used": "gemini-2.5-flash-preview-05-20",
    "api_key_used": "primary",
    "rate_limited": false
  },
  "review_comments": [
    {
      "file_path": "orchestrator/src/index.mjs",
      "github_diff_position": 227,
      "comment_text_md": "**My Confidence: High**\n\nThis issue from the previous review remains unaddressed. The `activeFetches` counter is decremented immediately after initiating a fetch promise (`currentPromise.then(resolve, reject);`). This means it decrements *before* the fetch operation has actually completed or settled, potentially leading to more concurrent fetches than `MAX_CONCURRENT_SENTENCE_FETCHES` allows.\nTo correctly manage concurrency, the `activeFetches--` and `processQueue()` calls must be placed within a `.finally()` block of the `currentPromise`. This ensures that a slot is freed and the queue is processed only when a fetch operation truly completes (either successfully or with an error).\n\n```javascript\n        // ... inside the processQueue loop ...\n        const currentPromise = (async () => {\n            // ... existing fetch logic ...\n            return result;\n        })();\n\n        outstandingPromises.add(currentPromise);\n        currentPromise.finally(() => {\n            activeFetches--; // Decrement when promise settles\n            outstandingPromises.delete(currentPromise);\n            processQueue(); // Attempt to process more from the queue\n        });\n\n        currentPromise.then(resolve, reject); // Resolve/reject the original promise\n        // REMOVE the old activeFetches--; and processQueue(); from here\n```",
      "ai_confidence": "High",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "concurrency"
    },
    {
      "file_path": "orchestrator/src/index.mjs",
      "github_diff_position": 87,
      "comment_text_md": "**My Confidence: High**\n\nThis critical error handling issue from the previous review is still present. The `await request.json()` call is not wrapped in a `try...catch` block. If the incoming request body is not valid JSON, this will throw an unhandled exception, resulting in a generic 500 error without a clear message to the client.\nPlease wrap this call in a `try...catch` block to gracefully handle JSON parsing errors and return a meaningful 400 Bad Request response.\n\n```javascript\n  try {\n    const { text, voiceId, apiKey } = await request.json();\n    if (!text || !voiceId || !apiKey) {\n      return new Response('Missing required parameters: text, voiceId, or apiKey', { status: 400 });\n    }\n    // ... rest of the code\n  } catch (error) {\n    console.error('Orchestrator: Error parsing request body:', error);\n    return new Response('Invalid JSON in request body', { status: 400 });\n  }\n```",
      "ai_confidence": "High",
      "detected_severity_heuristic": "critical",
      "detected_category_heuristic": "concurrency"
    },
    {
      "file_path": "orchestrator/src/index.mjs",
      "github_diff_position": 150,
      "comment_text_md": "**My Confidence: High**\n\nThe `sendSseMessage` function is called within the `if (jobCurrentSentenceIndex > 0 ...)` block (lines 127-133) before it has been defined (its definition is on lines 145-151). This will result in a runtime `ReferenceError`.\nTo fix this, move the definition of `sendSseMessage` to before any calls to it, ideally right after the `writer` and `encoder` are initialized.\n\n```javascript\nconst { readable, writable } = new TransformStream();\nconst writer = writable.getWriter();\nconst encoder = new TextEncoder();\n\n// Move this definition here\nconst sendSseMessage = (data, event = 'message') => {\n    let message = `event: ${event}\\n`;\n    message += `id: ${data.index}\\n`;\n    message += `data: ${JSON.stringify({ ...data, jobId })}\\n\\n`;\n    writer.write(encoder.encode(message));\n};\n\n// Now this call will work\nif (jobCurrentSentenceIndex > 0 && jobCurrentSentenceIndex < sentences.length) {\n    // ...\n    for (let i = 0; i < jobCurrentSentenceIndex; i++) {\n        if (jobAudioChunks[i]) {\n            sendSseMessage({ audioChunk: jobAudioChunks[i], index: i, mimeType: \"audio/opus\" });\n        }\n    }\n    // ...\n}\n```",
      "ai_confidence": "High",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "concurrency"
    },
    {
      "file_path": "orchestrator/src/index.mjs",
      "github_diff_position": 199,
      "comment_text_md": "**My Confidence: Medium**\n\nThis issue from the previous review remains unaddressed. The `targetService.fetch` call uses `new Request(request.url, {...})`, which passes the full original URL (e.g., `/api/tts?jobId=...`) to the backend TTS service. While this might work if the backend is configured to handle this specific path, it's more common and robust for an orchestrator to rewrite the path to a canonical backend endpoint (e.g., `/tts` or `/generate`).\nConsider constructing the URL for the backend fetch explicitly to ensure it matches the backend's expected endpoint, potentially stripping query parameters if they are not relevant to the backend TTS service.\n\n```javascript\n                                const backendTtsUrl = new URL(request.url); // Start with original URL\n                                backendTtsUrl.pathname = '/tts'; // Or whatever the backend's actual TTS endpoint is\n                                backendTtsUrl.search = ''; // Remove search params if not needed by backend\n\n                                const response = await targetService.fetch(new Request(backendTtsUrl.toString(), {\n                                    method: 'POST',\n                                    headers: {\n                                        'Content-Type': 'application/json',\n                                        'Authorization': `Bearer ${apiKey}`\n                                    },\n                                    body: JSON.stringify({ text: sentence.trim(), voiceId }),\n                                }));\n```",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "security"
    },
    {
      "file_path": "orchestrator/src/ttsStateDurableObject.mjs",
      "github_diff_position": 70,
      "comment_text_md": "**My Confidence: High**\n\nThe critical race condition identified in the previous review regarding the asynchronous `loadState()` call in the constructor and its interaction with `fetch` and `initialise` methods remains unaddressed.\nThe current check in `fetch`: `if (!this.initialised && (await this.state.storage.get(\"initialised\")) === false)` is insufficient. If `this.initialised` is `false` (because `loadState` hasn't completed yet) but `this.state.storage.get(\"initialised\")` returns `true` (because the DO was previously initialized), the `fetch` method will proceed with potentially uninitialized in-memory state variables (`this.text`, `this.voiceId`, `this.audioChunks`, etc.).\nSimilarly, the `initialise` method does not wait for the initial state load to complete, meaning its `if (this.initialised)` check is also susceptible to this race condition.\n\nTo ensure data consistency and prevent race conditions, the `loadState` promise should be stored in the constructor and awaited at the beginning of both `fetch` and `initialise` methods. This guarantees the Durable Object's state is fully loaded into memory before any request is processed or initialization logic is applied.\n\n```javascript\nexport class TTSStateDurableObject {\n    constructor(state, env) {\n        // ...\n        this.initialised = false;\n        this.loadStatePromise = this.loadState().then(() => {\n            this.initialised = true; // Set initialised to true on successful load\n            console.log(\"TTSStateDurableObject constructor: state loaded.\");\n        }).catch(error => {\n            console.error(\"TTSStateDurableObject constructor: failed to load state:\", error);\n            this.initialised = false;\n            throw error; // Re-throw to propagate the error to the promise chain\n        });\n    }\n\n    async initialise(text, voiceId) {\n        try {\n            await this.loadStatePromise; // Ensure initial state is loaded\n        } catch (error) {\n            console.error(\"TTSStateDurableObject initialise: initial state load failed.\", error);\n            // Decide how to handle this: throw, return error, or proceed with default\n            throw new Error(\"Failed to load initial state for initialization.\");\n        }\n\n        if (this.initialised) { // Now this.initialised is reliable\n            console.log(\"TTSStateDurableObject already initialised.\");\n            return;\n        }\n        // ... rest of initialise logic ...\n    }\n\n    async fetch(request) {\n        try {\n            await this.loadStatePromise; // Ensure state is loaded before processing any request\n        } catch (error) {\n            console.error(\"TTSStateDurableObject fetch: initial state load failed.\", error);\n            return new Response(\"Durable Object failed to initialize state.\", { status: 500 });\n        }\n\n        if (!this.initialised) { // Now this.initialised is guaranteed to reflect the loaded state\n             console.error(\"TTSStateDurableObject not initialized, cannot process request.\");\n             return new Response(\"Durable Object not initialized.\", { status: 500 });\n        }\n        // ... rest of fetch logic ...\n    }\n}\n```",
      "ai_confidence": "High",
      "detected_severity_heuristic": "critical",
      "detected_category_heuristic": "concurrency"
    },
    {
      "file_path": "orchestrator/src/ttsStateDurableObject.mjs",
      "github_diff_position": 54,
      "comment_text_md": "**My Confidence: Medium**\n\nThe `updateProgress` method still assigns `audioChunkBase64` directly to `this.audioChunks[sentenceIndex]`. As noted in the previous review, in a parallel processing scenario, if `sentenceIndex` is not sequential, this will result in a sparse array.\nWhile JavaScript supports sparse arrays, it's crucial that any code consuming the `audioChunks` array (e.g., via `getJobState()`) is explicitly aware of and correctly handles these potential `undefined` elements. For example, if the consumer expects a dense array or iterates over it without checking for `undefined`, it could lead to unexpected behavior or errors.\nConsider adding a note in the documentation for `getJobState` or `audioChunks` explaining this behavior, or if possible, transform the array to a dense one before returning it, e.g., by filtering out `undefined` values if they are truly \"missing\" or by using `Array.prototype.flat()` if the chunks are meant to be concatenated.",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "orchestrator/src/ttsStateDurableObject.mjs",
      "github_diff_position": 38,
      "comment_text_md": "**My Confidence: Low**\n\nThe `if (this.initialised)` check at the beginning of the `loadState` method might not behave as intended. When the Durable Object is first instantiated, `this.initialised` is set to `false` in the constructor. The `loadState()` call from the constructor will therefore always proceed, as `this.initialised` will be `false`.\nThe `this.initialised = true;` assignment happens *after* the state is loaded and assigned within `loadState`. This means the check only prevents redundant loads if `loadState` is explicitly called *again* on an already initialized instance, which is unlikely given the constructor's behavior.\nIf the intent is to prevent `loadState` from running if the object's in-memory state is already populated (e.g., after a successful initial load), then the `this.initialised` flag should be set *after* the state has been successfully loaded and assigned, and the `loadStatePromise` pattern (as suggested in the first comment) is the more robust way to ensure state readiness before processing requests, rather than relying on `loadState` to guard itself.",
      "ai_confidence": "Low",
      "detected_severity_heuristic": "medium",
      "detected_category_heuristic": "performance"
    },
    {
      "file_path": "orchestrator/src/utils/textProcessing.mjs",
      "github_diff_position": 5,
      "comment_text_md": "**My Confidence: High**\n\nThe `splitIntoSentences` function has expanded its list of abbreviations, which is an improvement. However, the list `(Mr|Mrs|Ms|Dr|Prof|Capt|Lt|Col|Gen|Rev|Fr|Sr|Jr|Maj|Gov|Sen|Rep|etc|e\\.g|i\\.e)` is still not exhaustive and could lead to incorrect sentence segmentation for other common abbreviations (e.g., \"Fig.\", \"No.\", \"Ave.\", \"St.\", \"Co.\", \"Inc.\", \"Ltd.\", \"Vol.\", \"Chap.\", \"p.\", \"pp.\", \"vs.\"). This could still negatively impact TTS output quality.\n\nConsider further expanding this list to cover more common cases. For a more robust and future-proof solution, especially if dealing with diverse text inputs, exploring a dedicated NLP library for sentence tokenization (e.g., `compromise` or `natural` in Node.js) might be beneficial to avoid maintaining a large, potentially incomplete, regex list.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "test/orchestrator/index.test.mjs",
      "github_diff_position": 78,
      "comment_text_md": "**My Confidence: High**\n\nRe-addressing previous comment. The test `should return 500 if RouterCounter fails to select a worker` still has a potentially fragile setup for the `env` object. By explicitly setting `env.BACKEND_SERVICE_0: mockBackendService1`, you introduce a service that might or might not be considered by the orchestrator's internal logic for discovering backend services (which typically iterates `BACKEND_SERVICE_1`, `BACKEND_SERVICE_2`, etc.).\n\nTo reliably test the scenario where no worker can be selected, it's best to ensure the `backendServices` array *within the orchestrator's logic* is truly empty. This can be achieved by simply setting `env.BACKEND_SERVICE_1 = undefined; env.BACKEND_SERVICE_2 = undefined;` and *not* adding `BACKEND_SERVICE_0`. This makes the test's intent clearer and less dependent on the exact implementation details of how the orchestrator discovers services beyond the standard `BACKEND_SERVICE_X` pattern.\n\nConsider simplifying the `env` setup in this test to:\n```javascript\ntest('should return 500 if RouterCounter fails to select a worker', async () => {\n  mockRouterCounterStub.fetch.mockResolvedValueOnce(new Response(\"999\"));\n  // Ensure no standard backend services are available for routing\n  env.BACKEND_SERVICE_1 = undefined;\n  env.BACKEND_SERVICE_2 = undefined;\n  // No need to redefine 'env' or add BACKEND_SERVICE_0.\n  // The orchestrator should then find an empty list of backend services.\n\n  const request = new Request('http://localhost/api/some-other-path', { method: 'GET' });\n  const response = await Worker.fetch(request, env, ctx);\n\n  expect(response.status).toBe(500);\n  expect(await response.text()).toBe('Failed to select target worker for routing.');\n});\n```",
      "ai_confidence": "High",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "test/orchestrator/index.test.mjs",
      "github_diff_position": 98,
      "comment_text_md": "**My Confidence: Medium**\n\nRe-addressing previous comment. The test `should call handleTtsRequest for /api/tts path` still uses `jest.spyOn(Worker, 'fetch').mockImplementationOnce(...)` to completely replace the `Worker.fetch` function. This means the test is verifying its *own mock's* routing logic, not the orchestrator's actual `Worker.fetch` function's internal delegation to `handleTtsRequest`.\n\nWhile `handleTtsRequest` is not exported, this test's current implementation doesn't truly verify the orchestrator's routing. If the goal is to confirm that the main `fetch` handler correctly identifies and delegates `/api/tts` requests, a more robust approach (if direct spying on `handleTtsRequest` is impossible) would be to assert that the *side effects* unique to `handleTtsRequest` (e.g., interactions with `TTS_STATE_DO`) occur only when the `/api/tts` path is hit, and not for other paths.\n\nGiven the current structure, this test remains limited in its ability to verify the orchestrator's internal routing mechanism itself.",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "state-management"
    },
    {
      "file_path": "test/orchestrator/index.test.mjs",
      "github_diff_position": 191,
      "comment_text_md": "**My Confidence: High**\n\nThe test `should handle Durable Object state retrieval failure gracefully (new job assumed)` (lines 191-203) simulates `mockTtsStateStub.fetch` rejecting with an error when attempting to `get-state`. The test then asserts that the orchestrator proceeds to `initialize` a new job.\n\nThis behavior might be problematic. If `get-state` fails due to a network error or an internal Durable Object issue (not a 404 \"not found\" response), assuming it's a *new job* and initializing it could lead to data loss or inconsistent state if a job for that `jobId` actually existed but was temporarily unreachable.\n\nIt's generally safer to distinguish between a \"not found\" scenario (where a 404 response from `get-state` would be appropriate) and a \"failure to retrieve\" scenario (where a network error or 5xx response occurs). For a retrieval *failure*, the orchestrator should ideally return a 500 error to the client, or implement robust retry logic for `get-state` calls, rather than assuming a new job.\n\nConsider modifying the orchestrator's logic to handle `get-state` errors more explicitly, perhaps by returning a 500 status if the Durable Object state cannot be retrieved due to an unexpected error.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "critical",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "test/orchestrator/utils/textProcessing.test.mjs",
      "github_diff_position": 66,
      "comment_text_md": "**My Confidence: Medium**\n\nThis PR adds good test coverage for `splitIntoSentences`. However, my previous comment regarding multi-period abbreviations like \"U.S.A.\" or \"Ph.D.\" is still pending. These should typically not cause a sentence split. Please add a test case for this scenario.\n\nExample:\n```javascript\ntest('should handle multi-period abbreviations like \"U.S.A.\" without splitting', () => {\n  const text = 'U.S.A. is a country. It is big.';\n  expect(splitIntoSentences(text)).toEqual(['U.S.A. is a country.', 'It is big.']);\n});\n```",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "testing"
    },
    {
      "file_path": "test/orchestrator/utils/textProcessing.test.mjs",
      "github_diff_position": 66,
      "comment_text_md": "**My Confidence: Medium**\n\nMy previous comment about handling ellipses (`...`) is also still pending. An ellipsis should generally be treated as part of the sentence, not as a sentence terminator. Please add a test case for this.\n\nExample:\n```javascript\ntest('should handle ellipses without splitting', () => {\n  const text = 'He paused... and then spoke. What happened...?';\n  expect(splitIntoSentintoSentences(text)).toEqual(['He paused... and then spoke.', 'What happened...?']);\n});\n```",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "testing"
    },
    {
      "file_path": "test/tts/index.test.mjs",
      "github_diff_position": 525,
      "comment_text_md": "**My Confidence: High**\n\nThe previous review comment regarding the incorrect mocking of `window.AudioContext` in the `should process audio chunks and play them` test has not been fully addressed.\n\nCurrently, `MockAudioContext` is defined as a class (lines 64-117), and `Object.defineProperty(window, 'AudioContext', { value: MockAudioContext });` sets `window.AudioContext` to this class.\n\nInside the test, the lines `const mockAudioContextInstance = new MockAudioContext();` (line 527) and `window.AudioContext.mockImplementation(() => mockAudioContextInstance);` (line 530) are problematic. The `mockImplementation` method cannot be called on a plain class constructor. More importantly, the `AudioContext` instance (`audioContext`) created by the application code (inside `eventSource.onopen` at line 330) is a *different* instance from `mockAudioContextInstance` that the test creates.\n\nTherefore, assertions like `expect(mockAudioContextInstance.decodeAudioData).toHaveBeenCalled()` will not correctly reflect the application's behavior because the `decodeAudioData` method on the *application's* `audioContext` instance was called, not the one the test is holding.\n\nTo properly mock the `AudioContext` constructor and inspect the instance created by the application, `MockAudioContext` itself should be a Jest mock function constructor.\n\n**Suggested change:**\n\n1.  **Modify `MockAudioContext` definition (lines 64-117):**\n    Change `class MockAudioContext { ... }` to:\n    ```javascript\n    const MockAudioContext = jest.fn(function() {\n      this.decodeAudioData = jest.fn(buffer => {\n        return Promise.resolve(new MockAudioBuffer(1, 44100, 44100));\n      });\n      this.createBuffer = jest.fn((channels, length, sampleRate) => {\n        return new MockAudioBuffer(channels, length, sampleRate);\n      });\n      this.createBufferSource = jest.fn(() => new MockAudioBufferSourceNode());\n      this.destination = {};\n      this.currentTime = 0;\n      this.baseLatency = 0;\n    });\n    ```\n    (Keep `Object.defineProperty(window, 'AudioContext', { value: MockAudioContext });` and `Object.defineProperty(window, 'webkitAudioContext', { value: MockAudioContext });` as they are.)\n\n2.  **Modify the test `should process audio chunks and play them` (lines 525-548):**\n    Remove the lines that create `mockAudioContextInstance` and `mockAudioBufferSourceNodeInstance` *before* the `_simulateOpen()` call, and the `window.AudioContext.mockImplementation` line. Instead, retrieve the instance created by the application:\n    ```javascript\n    it('should process audio chunks and play them', async () => {\n      textInput.value = 'Test text';\n      apiKeyInput.value = 'test-api-key';\n      dispatchClick(speakButton);\n\n      mockEventSourceInstance._simulateOpen(); // This triggers new (window.AudioContext || window.webkitAudioContext)()\n\n      // Retrieve the AudioContext instance created by the application code\n      // This works because MockAudioContext is now a jest.fn() constructor\n      const scriptAudioContextInstance = MockAudioContext.mock.instances[0];\n      expect(scriptAudioContextInstance).toBeDefined(); // Ensure an instance was created\n\n      // Mock the createBufferSource method on the *actual* instance used by the script\n      const mockAudioBufferSourceNodeInstance = new MockAudioBufferSourceNode();\n      scriptAudioContextInstance.createBufferSource.mockReturnValue(mockAudioBufferSourceNodeInstance);\n\n      // Simulate first audio chunk\n      mockEventSourceInstance._simulateMessage({ audioChunk: btoa('raw_audio_data_1'), index: 0, mimeType: 'audio/opus' });\n      await Promise.resolve(); // Allow promises to resolve\n\n      expect(atob).toHaveBeenCalledWith('raw_audio_data_1');\n      expect(scriptAudioContextInstance.decodeAudioData).toHaveBeenCalled();\n      expect(scriptAudioContextInstance.createBufferSource).toHaveBeenCalled();\n      expect(mockAudioBufferSourceNodeInstance.buffer).toBeInstanceOf(MockAudioBuffer);\n      expect(mockAudioBufferSourceNodeInstance.connect).toHaveBeenCalledWith(scriptAudioContextInstance.destination);\n      expect(mockAudioBufferSourceNodeInstance.start).toHaveBeenCalled();\n\n      // Simulate second audio chunk\n      mockEventSourceInstance._simulateMessage({ audioChunk: btoa('raw_audio_data_2'), index: 1, mimeType: 'audio/opus' });\n      await Promise.resolve(); // Allow promises to resolve\n\n      // Simulate end of first chunk playback\n      mockAudioBufferSourceNodeInstance.onended();\n      await Promise.resolve(); // Allow promises to resolve\n\n      // Should play next chunk\n      expect(mockAudioBufferSourceNodeInstance.start).toHaveBeenCalledTimes(2);\n    });\n    ```\nThis ensures the test is asserting on the correct `AudioContext` instance and its methods, making the test reliable.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "test/tts/ttsClient.test.mjs",
      "github_diff_position": 361,
      "comment_text_md": "**My Confidence: Medium**\n\nIn the `should handle highlighting for words` test, the assertions for `clearAllHighlights` are incomplete. When `clearAllHighlights` is expected to run (e.g., on chunk end or stream end), it should iterate over all highlighted words and remove the `highlighted-word` class.\n\nCurrently, the test only asserts `expect(mockTextDisplayArea.querySelectorAll()[0].classList.remove).toHaveBeenCalled();` which only checks the first mock word element. To fully verify `clearAllHighlights`, you should assert that `classList.remove('highlighted-word')` was called on *all* relevant word elements that were previously highlighted. For example, if there are two mocked word elements, you should assert on both `mockTextDisplayArea.querySelectorAll()[0]` and `mockTextDisplayArea.querySelectorAll()[1]`.",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "testing"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 49,
      "comment_text_md": "**My Confidence: High**\n\nThe `EventSource` constructor does not support the `headers` option directly. The `Authorization` header will likely be ignored, leading to authentication failures if the backend requires it. For requests requiring custom headers, consider using `fetch` with `Response.body.getReader()` for streaming, or `XMLHttpRequest`.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "security"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 50,
      "comment_text_md": "**My Confidence: High**\n\nThe `text` parameter is still sent directly in the URL query string. For longer texts, this can exceed typical URL length limits (e.g., 2048 characters for many browsers/servers), leading to request failures. Consider sending the `text` in the request body (e.g., using a POST request) instead of a GET request with query parameters, especially for potentially large inputs.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "general"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 90,
      "comment_text_md": "**My Confidence: High**\n\nThe logic for mapping `data.text` (the current sentence from the TTS service) to the client-side `words` array for highlighting and progress tracking is still fragile. It assumes a perfect match between the client-side word splitting (`text.split`) and the sentences returned by the TTS service. If the TTS service performs any text normalization, punctuation handling, or returns sentences that don't perfectly align with the client's word segmentation, the highlighting and progress bar will be inaccurate or break. A more robust approach would be for the TTS service to return word-level timing information (e.g., `start_time`, `end_time`, `word_text`, `word_index_in_original_text`) along with the audio chunks. This would allow for precise highlighting and progress tracking independent of client-side text splitting.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "style/clarity"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 111,
      "comment_text_md": "**My Confidence: Medium**\n\nWhile `audioQueue.sort` helps with out-of-order chunk delivery, the condition `lastPlayedIndex < index` means playback will still stall indefinitely if a chunk with `index` is truly missing (e.g., due to network loss). Even if subsequent chunks (`index+1`, `index+2`) have arrived, they won't be played. Consider adding a timeout mechanism or a strategy to skip missing chunks after a certain delay to prevent complete stalling. For example, if `audioQueue` contains `index+N` but `index` is expected, after `X` seconds, play `index+N` and log a warning about the missing chunk.",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "performance"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 3,
      "comment_text_md": "**My Confidence: High**\n\nThe constants `SENTENCE_FETCH_TIMEOUT_MS` and `FIRST_SENTENCE_TIMEOUT_MS` are declared but not used anywhere in the provided code. They can be removed or implemented if they are intended for future functionality.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "performance"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 227,
      "comment_text_md": "**My Confidence: High**\n\nThe `playedTextLength` calculation for the progress bar is inaccurate. The `words` array includes separator elements (spaces, punctuation) which do not get a `sentenceIndex` assigned in the `onmessage` handler. Therefore, `words.filter(w => w.sentenceIndex !== -1 && w.sentenceIndex <= index)` will exclude all separators, making `playedTextLength` shorter than the actual spoken text length and causing the progress bar to report incorrect progress. Ensure all parts of the text are accounted for in the progress calculation, or refine the `words` array to only contain highlightable units.",
      "ai_confidence": "High",
      "detected_severity_heuristic": "high",
      "detected_category_heuristic": "bug"
    },
    {
      "file_path": "tts/ttsClient.mjs",
      "github_diff_position": 233,
      "comment_text_md": "**My Confidence: Medium**\n\nSimilar to the progress bar issue, the highlighting logic `word.element && word.sentenceIndex === currentSentenceIndex` will only highlight actual 'words' (alphanumeric sequences) and will skip separators (spaces, punctuation) because they never receive a `sentenceIndex`. This can lead to incomplete-looking highlighting. Additionally, the `currentHighlightedWordIndex` variable is declared but never used, suggesting a potential remnant of previous logic or an unused feature.",
      "ai_confidence": "Medium",
      "detected_severity_heuristic": "low",
      "detected_category_heuristic": "general"
    }
  ]
}